{
    "arxiv_id": "2412.19252",
    "title": "Localized exploration in contextual dynamic pricing achieves dimension-free regret",
    "authors": [
        {
            "name": "J Chai",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "Y Duan",
            "citations_all": 715,
            "citations_recent": 706,
            "h_index_all": 11,
            "h_index_recent": 11,
            "i10_index_all": 12,
            "i10_index_recent": 11
        },
        {
            "name": "J Fan",
            "citations_all": 99040,
            "citations_recent": 43017,
            "h_index_all": 130,
            "h_index_recent": 97,
            "i10_index_all": 368,
            "i10_index_recent": 278
        },
        {
            "name": "K Wang",
            "citations_all": 2005,
            "citations_recent": 1817,
            "h_index_all": 13,
            "h_index_recent": 13,
            "i10_index_all": 13,
            "i10_index_recent": 13
        }
    ],
    "abstract": "We study the problem of contextual dynamic pricing with a linear demand model. We propose a novel localized exploration-then-commit (LetC) algorithm which starts with a pure exploration stage, followed by a refinement stage that explores near the learned optimal pricing policy, and finally enters a pure exploitation stage. The algorithm is shown to achieve a minimax optimal, dimension-free regret bound when the time horizon exceeds a polynomial of the covariate dimension. Furthermore, we provide a general theoretical framework that encompasses the entire time spectrum, demonstrating how to balance exploration and exploitation when the horizon is limited. The analysis is powered by a novel critical inequality that depicts the exploration-exploitation trade-off in dynamic pricing, mirroring its existing counterpart for the bias-variance trade-off in regularized regression. Our theoretical results are validated by extensive experiments on synthetic and real-world data.",
    "published_date": "2024-12-26T00:00:00",
    "last_revised_date": "2024-12-26T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2412.19252.pdf",
    "primary_category": "Machine Learning (stat.ML)",
    "categories": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
    ],
    "keywords": null,
    "num_pages": 60,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2025": 2
    },
    "citationCount": 2,
    "venue": {
        "name": "arXiv.org",
        "type": null
    },
    "citations": [],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}