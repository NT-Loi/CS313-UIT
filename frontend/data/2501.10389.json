{
    "arxiv_id": "2501.10389",
    "title": "Transparency, Security, and Workplace Training & Awareness in the Age of Generative AI",
    "authors": [
        {
            "name": "L Vaishnav",
            "citations_all": 13,
            "citations_recent": 13,
            "h_index_all": 1,
            "h_index_recent": 1,
            "i10_index_all": 1,
            "i10_index_recent": 1
        },
        {
            "name": "S Singh",
            "citations_all": 4,
            "citations_recent": 4,
            "h_index_all": 1,
            "h_index_recent": 1,
            "i10_index_all": 0,
            "i10_index_recent": 0
        },
        {
            "name": "KA Cornell",
            "citations_all": 96,
            "citations_recent": 48,
            "h_index_all": 4,
            "h_index_recent": 2,
            "i10_index_all": 2,
            "i10_index_recent": 2
        }
    ],
    "abstract": "This paper investigates the impacts of the rapidly evolving landscape of generative Artificial Intelligence (AI) development. Emphasis is given to how organizations grapple with a critical imperative: reevaluating their policies regarding AI usage in the workplace. As AI technologies advance, ethical considerations, transparency, data privacy, and their impact on human labor intersect with the drive for innovation and efficiency. Our research explores publicly accessible large language models (LLMs) that often operate on the periphery, away from mainstream scrutiny. These lesser-known models have received limited scholarly analysis and may lack comprehensive restrictions and safeguards. Specifically, we examine Gab AI, a platform that centers around unrestricted communication and privacy, allowing users to interact freely without censorship. Generative AI chatbots are increasingly prevalent, but cybersecurity risks have also escalated. Organizations must carefully navigate this evolving landscape by implementing transparent AI usage policies. Frequent training and policy updates are essential to adapt to emerging threats. Insider threats, whether malicious or unwitting, continue to pose one of the most significant cybersecurity challenges in the workplace. Our research is on the lesser-known publicly accessible LLMs and their implications for workplace policies. We contribute to the ongoing discourse on AI ethics, transparency, and security by emphasizing the need for well-thought-out guidelines and vigilance in policy maintenance.",
    "published_date": "2024-12-19T00:00:00",
    "last_revised_date": "2024-12-19T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2501.10389.pdf",
    "primary_category": "Computers and Society (cs.CY)",
    "categories": [
        "Computers and Society (cs.CY)"
    ],
    "keywords": null,
    "num_pages": 24,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2025": 1
    },
    "citationCount": 1,
    "venue": {
        "name": "arXiv.org",
        "type": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 58,
            "citationCount": 1,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}