{
    "arxiv_id": "2412.18647",
    "title": "Nationality, Race, and Ethnicity Biases in and Consequences of Detecting AI-Generated Self-Presentations",
    "authors": [
        {
            "name": "H Chu",
            "citations_all": 1764,
            "citations_recent": 1713,
            "h_index_all": 21,
            "h_index_recent": 21,
            "i10_index_all": 26,
            "i10_index_recent": 26
        },
        {
            "name": "LR Men",
            "citations_all": 14042,
            "citations_recent": 10932,
            "h_index_all": 53,
            "h_index_recent": 49,
            "i10_index_all": 89,
            "i10_index_recent": 88
        },
        {
            "name": "S Liu",
            "citations_all": 934,
            "citations_recent": 932,
            "h_index_all": 15,
            "h_index_recent": 15,
            "i10_index_all": 18,
            "i10_index_recent": 18
        },
        {
            "name": "S Yuan",
            "citations_all": 8299,
            "citations_recent": 7659,
            "h_index_all": 27,
            "h_index_recent": 27,
            "i10_index_all": 41,
            "i10_index_recent": 41
        },
        {
            "name": "Y Sun",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        }
    ],
    "abstract": "This study builds on person perception and human AI interaction (HAII) theories to investigate how content and source cues, specifically race, ethnicity, and nationality, affect judgments of AI-generated content in a high-stakes self-presentation context: college applications. Results of a pre-registered experiment with a nationally representative U.S. sample (N = 644) show that content heuristics, such as linguistic style, played a dominant role in AI detection. Source heuristics, such as nationality, also emerged as a significant factor, with international students more likely to be perceived as using AI, especially when their statements included AI-sounding features. Interestingly, Asian and Hispanic applicants were more likely to be judged as AI users when labeled as domestic students, suggesting interactions between racial stereotypes and AI detection. AI attribution led to lower perceptions of personal statement quality and authenticity, as well as negative evaluations of the applicant's competence, sociability, morality, and future success.",
    "published_date": "2024-12-24T00:00:00",
    "last_revised_date": "2024-12-24T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2412.18647.pdf",
    "primary_category": "Artificial Intelligence (cs.AI)",
    "categories": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
    ],
    "keywords": null,
    "num_pages": 13,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {},
    "citationCount": 0,
    "venue": {
        "name": "arXiv.org",
        "type": null
    },
    "citations": [],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}