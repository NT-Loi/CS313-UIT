{
    "arxiv_id": "2501.01880",
    "title": "Long Context vs. RAG for LLMs: An Evaluation and Revisits",
    "authors": [
        {
            "name": "X Li",
            "citations_all": 359,
            "citations_recent": 359,
            "h_index_all": 6,
            "h_index_recent": 6,
            "i10_index_all": 6,
            "i10_index_recent": 6
        },
        {
            "name": "Y Cao",
            "citations_all": 10209,
            "citations_recent": 9882,
            "h_index_all": 38,
            "h_index_recent": 37,
            "i10_index_all": 76,
            "i10_index_recent": 74
        },
        {
            "name": "Y Ma",
            "citations_all": 991,
            "citations_recent": 991,
            "h_index_all": 14,
            "h_index_recent": 14,
            "i10_index_all": 14,
            "i10_index_recent": 14
        },
        {
            "name": "A Sun",
            "citations_all": 24080,
            "citations_recent": 15419,
            "h_index_all": 70,
            "h_index_recent": 53,
            "i10_index_all": 198,
            "i10_index_recent": 146
        }
    ],
    "abstract": "Extending context windows (i.e., Long Context, LC) and using retrievers to selectively access relevant information (i.e., Retrieval-Augmented Generation, RAG) are the two main strategies to enable LLMs to incorporate extremely long external contexts. This paper revisits recent studies on this topic, highlighting their key insights and discrepancies. We then provide a more comprehensive evaluation by filtering out questions answerable without external context, identifying the most effective retrieval methods, and expanding the datasets. We show that LC generally outperforms RAG in question-answering benchmarks, especially for Wikipedia-based questions. Summarization-based retrieval performs comparably to LC, while chunk-based retrieval lags behind. However, RAG has advantages in dialogue-based and general question queries. These insights underscore the trade-offs between RAG and LC strategies, offering guidance for future optimization of LLMs with external knowledge sources. We also provide an in-depth discussion on this topic, highlighting the overlooked importance of context relevance in existing studies.",
    "published_date": "2024-12-27T00:00:00",
    "last_revised_date": "2024-12-27T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2501.01880.pdf",
    "primary_category": "Computation and Language (cs.CL)",
    "categories": [
        "Computation and Language (cs.CL)"
    ],
    "keywords": null,
    "num_pages": 18,
    "github_stars": 10,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2025": 18
    },
    "citationCount": 18,
    "venue": {
        "name": "arXiv.org",
        "type": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 120,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 57,
            "citationCount": 1,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 16,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 25,
            "citationCount": 1,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 39,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 31,
            "citationCount": 3,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 368,
            "citationCount": 16,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 52,
            "citationCount": 9,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 63,
            "citationCount": 1,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 40,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 36,
            "citationCount": 5,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 30,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 85,
            "citationCount": 23,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 36,
            "citationCount": 1,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}