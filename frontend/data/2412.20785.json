{
    "arxiv_id": "2412.20785",
    "title": "Accelerating Energy-Efficient Federated Learning in Cell-Free Networks with Adaptive Quantization",
    "authors": [
        {
            "name": "A Mahmoudi",
            "citations_all": 64,
            "citations_recent": 64,
            "h_index_all": 5,
            "h_index_recent": 5,
            "i10_index_all": 3,
            "i10_index_recent": 3
        },
        {
            "name": "M Xiao",
            "citations_all": 16462,
            "citations_recent": 12499,
            "h_index_all": 56,
            "h_index_recent": 43,
            "i10_index_all": 213,
            "i10_index_recent": 158
        },
        {
            "name": "E Bj√∂rnson",
            "citations_all": 40460,
            "citations_recent": 31226,
            "h_index_all": 91,
            "h_index_recent": 79,
            "i10_index_all": 304,
            "i10_index_recent": 269
        }
    ],
    "abstract": "Federated Learning (FL) enables clients to share learning parameters instead of local data, reducing communication overhead. Traditional wireless networks face latency challenges with FL. In contrast, Cell-Free Massive MIMO (CFmMIMO) can serve multiple clients on shared resources, boosting spectral efficiency and reducing latency for large-scale FL. However, clients' communication resource limitations can hinder the completion of the FL training. To address this challenge, we propose an energy-efficient, low-latency FL framework featuring optimized uplink power allocation for seamless client-server collaboration. Our framework employs an adaptive quantization scheme, dynamically adjusting bit allocation for local gradient updates to reduce communication costs. We formulate a joint optimization problem covering FL model updates, local iterations, and power allocation, solved using sequential quadratic programming (SQP) to balance energy and latency. Additionally, clients use the AdaDelta method for local FL model updates, enhancing local model convergence compared to standard SGD, and we provide a comprehensive analysis of FL convergence with AdaDelta local updates. Numerical results show that, within the same energy and latency budgets, our power allocation scheme outperforms the Dinkelbach and max-sum rate methods by increasing the test accuracy up to $7$\\% and $19$\\%, respectively. Moreover, for the three power allocation methods, our proposed quantization scheme outperforms AQUILA and LAQ by increasing test accuracy by up to $36$\\% and $35$\\%, respectively.",
    "published_date": "2024-12-30T00:00:00",
    "last_revised_date": "2024-12-30T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2412.20785.pdf",
    "primary_category": "Machine Learning (cs.LG)",
    "categories": [
        "Machine Learning (cs.LG)"
    ],
    "keywords": null,
    "num_pages": 17,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {},
    "citationCount": 1,
    "venue": {
        "name": "IEEE Transactions on Machine Learning in Communications and Networking",
        "type": "journal"
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 53,
            "citationCount": 0,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 36,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 27,
            "citationCount": 1,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 60,
            "citationCount": 5,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 38,
            "citationCount": 9,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 17,
            "citationCount": 4,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 38,
            "citationCount": 12,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 61,
            "citationCount": 19,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 46,
            "citationCount": 6,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 34,
            "citationCount": 11,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 50,
            "citationCount": 16,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 20,
            "citationCount": 7,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 33,
            "citationCount": 73,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 0,
            "citationCount": 17,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 50,
            "citationCount": 11,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 42,
            "citationCount": 25,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 34,
            "citationCount": 67,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 18,
            "citationCount": 31,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 0,
            "citationCount": 161,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 61,
            "citationCount": 257,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 24,
            "citationCount": 118,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 217,
            "citationCount": 607,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 40,
            "citationCount": 118,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 28,
            "citationCount": 167,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 54,
            "citationCount": 1598,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 52,
            "citationCount": 729,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 58,
            "citationCount": 145,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 50,
            "citationCount": 2573,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 45,
            "citationCount": 534,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 341,
            "citationCount": 17423,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 53,
            "citationCount": 383,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 26,
            "citationCount": 4894,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 49,
            "citationCount": 2178,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 58,
            "citationCount": 254,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 8,
            "citationCount": 6689,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 51,
            "citationCount": 14,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 0,
    "embedding": null
}