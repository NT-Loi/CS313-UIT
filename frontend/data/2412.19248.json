{
    "arxiv_id": "2412.19248",
    "title": "Causal Speech Enhancement with Predicting Semantics based on Quantized Self-supervised Learning Features",
    "authors": [
        {
            "name": "E Tsunoo",
            "citations_all": 972,
            "citations_recent": 735,
            "h_index_all": 16,
            "h_index_recent": 13,
            "i10_index_all": 27,
            "i10_index_recent": 20
        },
        {
            "name": "Y Saito",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "W Nakata",
            "citations_all": 526,
            "citations_recent": 526,
            "h_index_all": 6,
            "h_index_recent": 6,
            "i10_index_all": 5,
            "i10_index_recent": 5
        },
        {
            "name": "H Saruwatari",
            "citations_all": 12345,
            "citations_recent": 5128,
            "h_index_all": 49,
            "h_index_recent": 33,
            "i10_index_all": 271,
            "i10_index_recent": 116
        }
    ],
    "abstract": "Real-time speech enhancement (SE) is essential to online speech communication. Causal SE models use only the previous context while predicting future information, such as phoneme continuation, may help performing causal SE. The phonetic information is often represented by quantizing latent features of self-supervised learning (SSL) models. This work is the first to incorporate SSL features with causality into an SE model. The causal SSL features are encoded and combined with spectrogram features using feature-wise linear modulation to estimate a mask for enhancing the noisy input speech. Simultaneously, we quantize the causal SSL features using vector quantization to represent phonetic characteristics as semantic tokens. The model not only encodes SSL features but also predicts the future semantic tokens in multi-task learning (MTL). The experimental results using VoiceBank + DEMAND dataset show that our proposed method achieves 2.88 in PESQ, especially with semantic prediction MTL, in which we confirm that the semantic prediction played an important role in causal SE.",
    "published_date": "2024-12-26T00:00:00",
    "last_revised_date": "2024-12-26T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2412.19248.pdf",
    "primary_category": "Audio and Speech Processing (eess.AS)",
    "categories": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
    ],
    "keywords": null,
    "num_pages": 5,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {},
    "citationCount": 1,
    "venue": {
        "name": "arXiv.org",
        "type": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 27,
            "citationCount": 0,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}