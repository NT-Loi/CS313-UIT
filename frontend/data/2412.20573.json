{
    "arxiv_id": "2412.20573",
    "title": "The intrinsic motivation of reinforcement and imitation learning for sequential tasks",
    "authors": [
        {
            "name": "SM Nguyen",
            "citations_all": 1483,
            "citations_recent": 1088,
            "h_index_all": 21,
            "h_index_recent": 19,
            "i10_index_all": 28,
            "i10_index_recent": 25
        }
    ],
    "abstract": "This work in the field of developmental cognitive robotics aims to devise a new domain bridging between reinforcement learning and imitation learning, with a model of the intrinsic motivation for learning agents to learn with guidance from tutors multiple tasks, including sequential tasks. The main contribution has been to propose a common formulation of intrinsic motivation based on empirical progress for a learning agent to choose automatically its learning curriculum by actively choosing its learning strategy for simple or sequential tasks: which task to learn, between autonomous exploration or imitation learning, between low-level actions or task decomposition, between several tutors. The originality is to design a learner that benefits not only passively from data provided by tutors, but to actively choose when to request tutoring and what and whom to ask. The learner is thus more robust to the quality of the tutoring and learns faster with fewer demonstrations. We developed the framework of socially guided intrinsic motivation with machine learning algorithms to learn multiple tasks by taking advantage of the generalisability properties of human demonstrations in a passive manner or in an active manner through requests of demonstrations from the best tutor for simple and composing subtasks. The latter relies on a representation of subtask composition proposed for a construction process, which should be refined by representations used for observational processes of analysing human movements and activities of daily living. With the outlook of a language-like communication with the tutor, we investigated the emergence of a symbolic representation of the continuous sensorimotor space and of tasks using intrinsic motivation. We proposed within the reinforcement learning framework, a reward function for interacting with tutors for automatic curriculum learning in multi-task learning.",
    "published_date": "2024-12-29T00:00:00",
    "last_revised_date": "2024-12-29T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2412.20573.pdf",
    "primary_category": "Artificial Intelligence (cs.AI)",
    "categories": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
    ],
    "keywords": null,
    "num_pages": 73,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {},
    "citationCount": 0,
    "venue": {
        "name": "arXiv.org",
        "type": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 66,
            "citationCount": 1,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 26,
            "citationCount": 0,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}