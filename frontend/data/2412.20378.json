{
    "arxiv_id": "2412.20378",
    "title": "Tri-Ergon: Fine-grained Video-to-Audio Generation with Multi-modal Conditions and LUFS Control",
    "authors": [
        {
            "name": "B Li",
            "citations_all": 97,
            "citations_recent": 97,
            "h_index_all": 5,
            "h_index_recent": 5,
            "i10_index_all": 3,
            "i10_index_recent": 3
        },
        {
            "name": "F Yang",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "Y Mao",
            "citations_all": 875,
            "citations_recent": 875,
            "h_index_all": 17,
            "h_index_recent": 17,
            "i10_index_all": 19,
            "i10_index_recent": 19
        },
        {
            "name": "Q Ye",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "H Chen",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "Y Zhong",
            "citations_all": 4970,
            "citations_recent": 4860,
            "h_index_all": 33,
            "h_index_recent": 33,
            "i10_index_all": 66,
            "i10_index_recent": 63
        }
    ],
    "abstract": "Video-to-audio (V2A) generation utilizes visual-only video features to produce realistic sounds that correspond to the scene. However, current V2A models often lack fine-grained control over the generated audio, especially in terms of loudness variation and the incorporation of multi-modal conditions. To overcome these limitations, we introduce Tri-Ergon, a diffusion-based V2A model that incorporates textual, auditory, and pixel-level visual prompts to enable detailed and semantically rich audio synthesis. Additionally, we introduce Loudness Units relative to Full Scale (LUFS) embedding, which allows for precise manual control of the loudness changes over time for individual audio channels, enabling our model to effectively address the intricate correlation of video and audio in real-world Foley workflows. Tri-Ergon is capable of creating 44.1 kHz high-fidelity stereo audio clips of varying lengths up to 60 seconds, which significantly outperforms existing state-of-the-art V2A methods that typically generate mono audio for a fixed duration.",
    "published_date": "2024-12-29T00:00:00",
    "last_revised_date": "2024-12-29T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2412.20378.pdf",
    "primary_category": "Computer Vision and Pattern Recognition (cs.CV)",
    "categories": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
    ],
    "keywords": null,
    "num_pages": 12,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {},
    "citationCount": 8,
    "venue": {
        "name": "arXiv.org",
        "type": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 24,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 255,
            "citationCount": 2,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 21,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 26,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 55,
            "citationCount": 1,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 46,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 70,
            "citationCount": 10,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 93,
            "citationCount": 38,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}