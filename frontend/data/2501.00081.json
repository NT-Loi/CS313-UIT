{
    "arxiv_id": "2501.00081",
    "title": "Human-Centered Design for AI-based Automatically Generated Assessment Reports: A Systematic Review",
    "authors": [
        {
            "name": "E Latif",
            "citations_all": 1156,
            "citations_recent": 1150,
            "h_index_all": 16,
            "h_index_recent": 16,
            "i10_index_all": 23,
            "i10_index_recent": 23
        },
        {
            "name": "Y Chen",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "X Zhai",
            "citations_all": 7569,
            "citations_recent": 7361,
            "h_index_all": 42,
            "h_index_recent": 41,
            "i10_index_all": 91,
            "i10_index_recent": 88
        },
        {
            "name": "Y Yin",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        }
    ],
    "abstract": "This paper provides a comprehensive review of the design and implementation of automatically generated assessment reports (AutoRs) for formative use in K-12 Science, Technology, Engineering, and Mathematics (STEM) classrooms. With the increasing adoption of technology-enhanced assessments, there is a critical need for human-computer interactive tools that efficiently support the interpretation and application of assessment data by teachers. AutoRs are designed to provide synthesized, interpretable, and actionable insights into students' performance, learning progress, and areas for improvement. Guided by cognitive load theory, this study emphasizes the importance of reducing teachers' cognitive demands through user-centered and intuitive designs. It highlights the potential of diverse information presentation formats such as text, visual aids, and plots and advanced functionalities such as live and interactive features to enhance usability. However, the findings also reveal that many existing AutoRs fail to fully utilize these approaches, leading to high initial cognitive demands and limited engagement. This paper proposes a conceptual framework to inform the design, implementation, and evaluation of AutoRs, balancing the trade-offs between usability and functionality. The framework aims to address challenges in engaging teachers with technology-enhanced assessment results, facilitating data-driven decision-making, and providing personalized feedback to improve the teaching and learning process.",
    "published_date": "2024-12-30T00:00:00",
    "last_revised_date": "2024-12-30T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2501.00081.pdf",
    "primary_category": "Human-Computer Interaction (cs.HC)",
    "categories": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
    ],
    "keywords": [
        "Automatically Generated Assessment Reports (AutoRs)",
        "Formative Assessment",
        "Learning Analytics",
        "STEM Education",
        "Narrative-Driven Design"
    ],
    "num_pages": 26,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2025": 2
    },
    "citationCount": 2,
    "venue": {
        "name": "arXiv.org",
        "type": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 15,
            "citationCount": 1,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}