{
    "arxiv_id": "2412.19545",
    "title": "Enhancing Media Literacy: The Effectiveness of (Human) Annotations and Bias Visualizations on Bias Detection",
    "authors": [
        {
            "name": "T Spinde",
            "citations_all": 782,
            "citations_recent": 781,
            "h_index_all": 17,
            "h_index_recent": 17,
            "i10_index_all": 20,
            "i10_index_recent": 20
        },
        {
            "name": "F Wu",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "W Gaissmaier",
            "citations_all": 14240,
            "citations_recent": 6982,
            "h_index_all": 36,
            "h_index_recent": 28,
            "i10_index_all": 74,
            "i10_index_recent": 62
        },
        {
            "name": "G Demartini",
            "citations_all": 7356,
            "citations_recent": 4526,
            "h_index_all": 46,
            "h_index_recent": 36,
            "i10_index_all": 128,
            "i10_index_recent": 97
        },
        {
            "name": "2025 - Elsevier",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        }
    ],
    "abstract": "Marking biased texts is a practical approach to increase media bias awareness among news consumers. However, little is known about the generalizability of such awareness to new topics or unmarked news articles, and the role of machine-generated bias labels in enhancing awareness remains unclear. This study tests how news consumers may be trained and pre-bunked to detect media bias with bias labels obtained from different sources (Human or AI) and in various manifestations. We conducted two experiments with 470 and 846 participants, exposing them to various bias-labeling conditions. We subsequently tested how much bias they could identify in unlabeled news materials on new topics. The results show that both Human (t(467) = 4.55, p < .001, d = 0.42) and AI labels (t(467) = 2.49, p = .039, d = 0.23) increased correct detection compared to the control group. Human labels demonstrate larger effect sizes and higher statistical significance. The control group (t(467) = 4.51, p < .001, d = 0.21) also improves performance through mere exposure to study materials. We also find that participants trained with marked biased phrases detected bias most reliably (F(834,1) = 44.00, p < .001, {\\eta}2part = 0.048). Our experimental framework provides theoretical implications for systematically assessing the generalizability of learning effects in identifying media bias. These findings also provide practical implications for developing news-reading platforms that offer bias indicators and designing media literacy curricula to enhance media bias awareness.",
    "published_date": "2024-12-27T00:00:00",
    "last_revised_date": "2024-12-30T00:00:00",
    "num_revisions": 1,
    "pdf_url": "https://arxiv.org/pdf/2412.19545.pdf",
    "primary_category": "Human-Computer Interaction (cs.HC)",
    "categories": [
        "Human-Computer Interaction (cs.HC)"
    ],
    "keywords": null,
    "num_pages": 28,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {},
    "citationCount": 0,
    "venue": {
        "name": "arXiv.org",
        "type": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 73,
            "citationCount": 2,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}