{
    "arxiv_id": "2412.20742",
    "title": "UniRS: Unifying Multi-temporal Remote Sensing Tasks through Vision Language Models",
    "authors": [
        {
            "name": "Y Li",
            "citations_all": 25,
            "citations_recent": 25,
            "h_index_all": 3,
            "h_index_recent": 3,
            "i10_index_all": 0,
            "i10_index_recent": 0
        },
        {
            "name": "W Xu",
            "citations_all": 1119,
            "citations_recent": 1110,
            "h_index_all": 17,
            "h_index_recent": 17,
            "i10_index_all": 18,
            "i10_index_recent": 18
        },
        {
            "name": "G Li",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "Z Yu",
            "citations_all": 4,
            "citations_recent": 4,
            "h_index_all": 1,
            "h_index_recent": 1,
            "i10_index_all": 0,
            "i10_index_recent": 0
        },
        {
            "name": "Z Wei",
            "citations_all": 519,
            "citations_recent": 497,
            "h_index_all": 13,
            "h_index_recent": 13,
            "i10_index_all": 19,
            "i10_index_recent": 19
        },
        {
            "name": "J Wang",
            "citations_all": 2093,
            "citations_recent": 2092,
            "h_index_all": 14,
            "h_index_recent": 14,
            "i10_index_all": 16,
            "i10_index_recent": 16
        },
        {
            "name": "M Peng",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        }
    ],
    "abstract": "The domain gap between remote sensing imagery and natural images has recently received widespread attention and Vision-Language Models (VLMs) have demonstrated excellent generalization performance in remote sensing multimodal tasks. However, current research is still limited in exploring how remote sensing VLMs handle different types of visual inputs. To bridge this gap, we introduce \\textbf{UniRS}, the first vision-language model \\textbf{uni}fying multi-temporal \\textbf{r}emote \\textbf{s}ensing tasks across various types of visual input. UniRS supports single images, dual-time image pairs, and videos as input, enabling comprehensive remote sensing temporal analysis within a unified framework. We adopt a unified visual representation approach, enabling the model to accept various visual inputs. For dual-time image pair tasks, we customize a change extraction module to further enhance the extraction of spatiotemporal features. Additionally, we design a prompt augmentation mechanism tailored to the model's reasoning process, utilizing the prior knowledge of the general-purpose VLM to provide clues for UniRS. To promote multi-task knowledge sharing, the model is jointly fine-tuned on a mixed dataset. Experimental results show that UniRS achieves state-of-the-art performance across diverse tasks, including visual question answering, change captioning, and video scene classification, highlighting its versatility and effectiveness in unifying these multi-temporal remote sensing tasks. Our code and dataset will be released soon.",
    "published_date": "2024-12-30T00:00:00",
    "last_revised_date": "2024-12-30T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2412.20742.pdf",
    "primary_category": "Computer Vision and Pattern Recognition (cs.CV)",
    "categories": [
        "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "keywords": null,
    "num_pages": 12,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2025": 4
    },
    "citationCount": 4,
    "venue": {
        "name": "arXiv.org",
        "type": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 110,
            "citationCount": 0,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}