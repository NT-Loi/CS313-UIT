{
    "arxiv_id": "2412.20355",
    "title": "Confidence Interval Construction and Conditional Variance Estimation with Dense ReLU Networks",
    "authors": [
        {
            "name": "CMM Padilla",
            "citations_all": 73,
            "citations_recent": 73,
            "h_index_all": 4,
            "h_index_recent": 4,
            "i10_index_all": 3,
            "i10_index_recent": 3
        },
        {
            "name": "OHM Padilla",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "YL Kei",
            "citations_all": 78,
            "citations_recent": 78,
            "h_index_all": 4,
            "h_index_recent": 4,
            "i10_index_all": 1,
            "i10_index_recent": 1
        },
        {
            "name": "Z Zhang",
            "citations_all": 597,
            "citations_recent": 506,
            "h_index_all": 10,
            "h_index_recent": 10,
            "i10_index_all": 10,
            "i10_index_recent": 10
        },
        {
            "name": "Y Chen",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        }
    ],
    "abstract": "This paper addresses the problems of conditional variance estimation and confidence interval construction in nonparametric regression using dense networks with the Rectified Linear Unit (ReLU) activation function. We present a residual-based framework for conditional variance estimation, deriving nonasymptotic bounds for variance estimation under both heteroscedastic and homoscedastic settings. We relax the sub-Gaussian noise assumption, allowing the proposed bounds to accommodate sub-Exponential noise and beyond. Building on this, for a ReLU neural network estimator, we derive non-asymptotic bounds for both its conditional mean and variance estimation, representing the first result for variance estimation using ReLU networks. Furthermore, we develop a ReLU network based robust bootstrap procedure (Efron, 1992) for constructing confidence intervals for the true mean that comes with a theoretical guarantee on the coverage, providing a significant advancement in uncertainty quantification and the construction of reliable confidence intervals in deep learning settings.",
    "published_date": "2024-12-29T00:00:00",
    "last_revised_date": "2025-01-01T00:00:00",
    "num_revisions": 1,
    "pdf_url": "https://arxiv.org/pdf/2412.20355.pdf",
    "primary_category": "Machine Learning (stat.ML)",
    "categories": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
    ],
    "keywords": [
        "Inference",
        "bootstrap",
        "deep learning"
    ],
    "num_pages": 55,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2025": 2
    },
    "citationCount": 2,
    "venue": {
        "name": "arXiv.org",
        "type": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 39,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 65,
            "citationCount": 0,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}