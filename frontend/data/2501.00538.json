{
    "arxiv_id": "2501.00538",
    "title": "Adaptive Tabu Dropout for Regularization of Deep Neural Network",
    "authors": [
        {
            "name": "MT Hasan",
            "citations_all": 106,
            "citations_recent": 104,
            "h_index_all": 4,
            "h_index_recent": 4,
            "i10_index_all": 3,
            "i10_index_recent": 3
        },
        {
            "name": "A Akter",
            "citations_all": 90,
            "citations_recent": 88,
            "h_index_all": 2,
            "h_index_recent": 2,
            "i10_index_all": 2,
            "i10_index_recent": 2
        },
        {
            "name": "MN Shamael",
            "citations_all": 18,
            "citations_recent": 16,
            "h_index_all": 2,
            "h_index_recent": 2,
            "i10_index_all": 1,
            "i10_index_recent": 1
        },
        {
            "name": "MAE Hossain",
            "citations_all": 78,
            "citations_recent": 78,
            "h_index_all": 2,
            "h_index_recent": 2,
            "i10_index_all": 1,
            "i10_index_recent": 1
        },
        {
            "name": "HMM Billah",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "S Islam",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "S Shatabda",
            "citations_all": 3937,
            "citations_recent": 3425,
            "h_index_all": 34,
            "h_index_recent": 32,
            "i10_index_all": 83,
            "i10_index_recent": 73
        }
    ],
    "abstract": "Dropout is an effective strategy for the regularization of deep neural networks. Applying tabu to the units that have been dropped in the recent epoch and retaining them for training ensures diversification in dropout. In this paper, we improve the Tabu Dropout mechanism for training deep neural networks in two ways. Firstly, we propose to use tabu tenure, or the number of epochs a particular unit will not be dropped. Different tabu tenures provide diversification to boost the training of deep neural networks based on the search landscape. Secondly, we propose an adaptive tabu algorithm that automatically selects the tabu tenure based on the training performances through epochs. On several standard benchmark datasets, the experimental results show that the adaptive tabu dropout and tabu tenure dropout diversify and perform significantly better compared to the standard dropout and basic tabu dropout mechanisms.",
    "published_date": "2024-12-31T00:00:00",
    "last_revised_date": "2024-12-31T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2501.00538.pdf",
    "primary_category": "Machine Learning (cs.LG)",
    "categories": [
        "Machine Learning (cs.LG)"
    ],
    "keywords": [
        "Online Learning & Bandits Deep Neural Network Algorithms Reinforcement Learning Algorithms Heuristic Search Local Search"
    ],
    "num_pages": 13,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2024": 1,
        "2025": 1
    },
    "citationCount": 2,
    "venue": {
        "name": "International Conference on Neural Information Processing",
        "type": "conference"
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 48,
            "citationCount": 1,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}