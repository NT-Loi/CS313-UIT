{
    "arxiv_id": "2412.19152",
    "title": "To Predict or Not To Predict? Proportionally Masked Autoencoders for Tabular Data Imputation",
    "authors": [
        {
            "name": "J Kim",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "K Lee",
            "citations_all": 5600,
            "citations_recent": 5221,
            "h_index_all": 17,
            "h_index_recent": 15,
            "i10_index_all": 18,
            "i10_index_recent": 17
        },
        {
            "name": "T Park",
            "citations_all": 2124,
            "citations_recent": 1000,
            "h_index_all": 21,
            "h_index_recent": 16,
            "i10_index_all": 35,
            "i10_index_recent": 23
        }
    ],
    "abstract": "Masked autoencoders (MAEs) have recently demonstrated effectiveness in tabular data imputation. However, due to the inherent heterogeneity of tabular data, the uniform random masking strategy commonly used in MAEs can disrupt the distribution of missingness, leading to suboptimal performance. To address this, we propose a proportional masking strategy for MAEs. Specifically, we first compute the statistics of missingness based on the observed proportions in the dataset, and then generate masks that align with these statistics, ensuring that the distribution of missingness is preserved after masking. Furthermore, we argue that simple MLP-based token mixing offers competitive or often superior performance compared to attention mechanisms while being more computationally efficient, especially in the tabular domain with the inherent heterogeneity. Experimental results validate the effectiveness of the proposed proportional masking strategy across various missing data patterns in tabular datasets. Code is available at: \\url{this https URL}.",
    "published_date": "2024-12-26T00:00:00",
    "last_revised_date": "2024-12-26T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2412.19152.pdf",
    "primary_category": "Machine Learning (cs.LG)",
    "categories": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
    ],
    "keywords": null,
    "num_pages": 19,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {},
    "citationCount": 1,
    "venue": {
        "name": "arXiv.org",
        "type": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 34,
            "citationCount": 0,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}