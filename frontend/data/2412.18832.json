{
    "arxiv_id": "2412.18832",
    "title": "Structured Speaker-Deficiency Adaptation of Foundation Models for Dysarthric and Elderly Speech Recognition",
    "authors": [
        {
            "name": "S Hu",
            "citations_all": 718,
            "citations_recent": 717,
            "h_index_all": 16,
            "h_index_recent": 16,
            "i10_index_all": 18,
            "i10_index_recent": 18
        },
        {
            "name": "X Xie",
            "citations_all": 1086,
            "citations_recent": 1038,
            "h_index_all": 19,
            "h_index_recent": 19,
            "i10_index_all": 31,
            "i10_index_recent": 28
        },
        {
            "name": "M Geng",
            "citations_all": 1156,
            "citations_recent": 1153,
            "h_index_all": 22,
            "h_index_recent": 22,
            "i10_index_all": 29,
            "i10_index_recent": 29
        },
        {
            "name": "J Deng",
            "citations_all": 496,
            "citations_recent": 495,
            "h_index_all": 14,
            "h_index_recent": 14,
            "i10_index_all": 19,
            "i10_index_recent": 19
        },
        {
            "name": "Z Jin",
            "citations_all": 660,
            "citations_recent": 657,
            "h_index_all": 14,
            "h_index_recent": 14,
            "i10_index_all": 16,
            "i10_index_recent": 16
        },
        {
            "name": "T Wang",
            "citations_all": 834,
            "citations_recent": 833,
            "h_index_all": 17,
            "h_index_recent": 17,
            "i10_index_all": 19,
            "i10_index_recent": 19
        },
        {
            "name": "M Cui",
            "citations_all": 518,
            "citations_recent": 516,
            "h_index_all": 14,
            "h_index_recent": 14,
            "i10_index_all": 17,
            "i10_index_recent": 17
        },
        {
            "name": "G Li",
            "citations_all": 369,
            "citations_recent": 362,
            "h_index_all": 11,
            "h_index_recent": 11,
            "i10_index_all": 11,
            "i10_index_recent": 11
        },
        {
            "name": "Z Li",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "H Meng",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "X Liu",
            "citations_all": 29506,
            "citations_recent": 11132,
            "h_index_all": 44,
            "h_index_recent": 36,
            "i10_index_all": 156,
            "i10_index_recent": 114
        }
    ],
    "abstract": "Data-intensive fine-tuning of speech foundation models (SFMs) to scarce and diverse dysarthric and elderly speech leads to data bias and poor generalization to unseen speakers. This paper proposes novel structured speaker-deficiency adaptation approaches for SSL pre-trained SFMs on such data. Speaker and speech deficiency invariant SFMs were constructed in their supervised adaptive fine-tuning stage to reduce undue bias to training data speakers, and serves as a more neutral and robust starting point for test time unsupervised adaptation. Speech variability attributed to speaker identity and speech impairment severity, or aging induced neurocognitive decline, are modelled using separate adapters that can be combined together to model any seen or unseen speaker. Experiments on the UASpeech dysarthric and DementiaBank Pitt elderly speech corpora suggest structured speaker-deficiency adaptation of HuBERT and Wav2vec2-conformer models consistently outperforms baseline SFMs using either: a) no adapters; b) global adapters shared among all speakers; or c) single attribute adapters modelling speaker or deficiency labels alone by statistically significant WER reductions up to 3.01% and 1.50% absolute (10.86% and 6.94% relative) on the two tasks respectively. The lowest published WER of 19.45% (49.34% on very low intelligibility, 33.17% on unseen words) is obtained on the UASpeech test set of 16 dysarthric speakers.",
    "published_date": "2024-12-25T00:00:00",
    "last_revised_date": "2024-12-25T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2412.18832.pdf",
    "primary_category": "Audio and Speech Processing (eess.AS)",
    "categories": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
    ],
    "keywords": null,
    "num_pages": 5,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2025": 2
    },
    "citationCount": 2,
    "venue": {
        "name": "arXiv.org",
        "type": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 31,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 39,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 43,
            "citationCount": 0,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}