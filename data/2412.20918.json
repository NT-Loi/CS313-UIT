{
    "arxiv_id": "2412.20918",
    "title": "Uncertainty-Aware Out-of-Distribution Detection with Gaussian Processes",
    "authors": [
        {
            "name": "Y Chen",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "CL Sung",
            "citations_all": 420,
            "citations_recent": 373,
            "h_index_all": 10,
            "h_index_recent": 10,
            "i10_index_all": 12,
            "i10_index_recent": 12
        },
        {
            "name": "A Kusari",
            "citations_all": 427,
            "citations_recent": 324,
            "h_index_all": 9,
            "h_index_recent": 9,
            "i10_index_all": 9,
            "i10_index_recent": 9
        },
        {
            "name": "X Song",
            "citations_all": 89,
            "citations_recent": 89,
            "h_index_all": 3,
            "h_index_recent": 3,
            "i10_index_all": 3,
            "i10_index_recent": 3
        },
        {
            "name": "W Sun",
            "citations_all": 242,
            "citations_recent": 232,
            "h_index_all": 10,
            "h_index_recent": 10,
            "i10_index_all": 10,
            "i10_index_recent": 10
        }
    ],
    "abstract": "Deep neural networks (DNNs) are often constructed under the closed-world assumption, which may fail to generalize to the out-of-distribution (OOD) data. This leads to DNNs producing overconfident wrong predictions and can result in disastrous consequences in safety-critical applications. Existing OOD detection methods mainly rely on curating a set of OOD data for model training or hyper-parameter tuning to distinguish OOD data from training data (also known as in-distribution data or InD data). However, OOD samples are not always available during the training phase in real-world applications, hindering the OOD detection accuracy. To overcome this limitation, we propose a Gaussian-process-based OOD detection method to establish a decision boundary based on InD data only. The basic idea is to perform uncertainty quantification of the unconstrained softmax scores of a DNN via a multi-class Gaussian process (GP), and then define a score function to separate InD and potential OOD data based on their fundamental differences in the posterior predictive distribution from the GP. Two case studies on conventional image classification datasets and real-world image datasets are conducted to demonstrate that the proposed method outperforms the state-of-the-art OOD detection methods when OOD samples are not observed in the training phase.",
    "published_date": "2024-12-30T00:00:00",
    "last_revised_date": "2024-12-30T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2412.20918.pdf",
    "primary_category": "Machine Learning (stat.ML)",
    "categories": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
    ],
    "keywords": null,
    "num_pages": 25,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2025": 2
    },
    "citationCount": 2,
    "venue": {
        "name": "arXiv.org",
        "type": null,
        "ranking": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 63,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 29,
            "citationCount": 1,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 9,
            "citationCount": 0,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}