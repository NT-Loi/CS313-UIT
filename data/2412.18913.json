{
    "arxiv_id": "2412.18913",
    "title": "Robust Target Speaker Direction of Arrival Estimation",
    "authors": [
        {
            "name": "Z Li",
            "citations_all": 6,
            "citations_recent": 6,
            "h_index_all": 2,
            "h_index_recent": 2,
            "i10_index_all": 0,
            "i10_index_recent": 0
        },
        {
            "name": "S He",
            "citations_all": 244,
            "citations_recent": 244,
            "h_index_all": 10,
            "h_index_recent": 10,
            "i10_index_all": 11,
            "i10_index_recent": 11
        },
        {
            "name": "X Zhang",
            "citations_all": 1734,
            "citations_recent": 1456,
            "h_index_all": 22,
            "h_index_recent": 20,
            "i10_index_all": 44,
            "i10_index_recent": 39
        }
    ],
    "abstract": "In multi-speaker environments the direction of arrival (DOA) of a target speaker is key for improving speech clarity and extracting target speaker's voice. However, traditional DOA estimation methods often struggle in the presence of noise, reverberation, and particularly when competing speakers are present. To address these challenges, we propose RTS-DOA, a robust real-time DOA estimation system. This system innovatively uses the registered speech of the target speaker as a reference and leverages full-band and sub-band spectral information from a microphone array to estimate the DOA of the target speaker's voice. Specifically, the system comprises a speech enhancement module for initially improving speech quality, a spatial module for learning spatial information, and a speaker module for extracting voiceprint features. Experimental results on the LibriSpeech dataset demonstrate that our RTS-DOA system effectively tackles multi-speaker scenarios and established new optimal benchmarks.",
    "published_date": "2024-12-25T00:00:00",
    "last_revised_date": "2024-12-25T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2412.18913.pdf",
    "primary_category": "Sound (cs.SD)",
    "categories": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
    ],
    "keywords": null,
    "num_pages": 5,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {},
    "citationCount": 3,
    "venue": {
        "name": "arXiv.org",
        "type": null,
        "ranking": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 31,
            "citationCount": 2,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}