{
    "arxiv_id": "2112.11055",
    "title": "A Scalable Deep Reinforcement Learning Model for Online Scheduling Coflows of Multi-Stage Jobs for High Performance Computing",
    "authors": [
        {
            "name": "X Wang",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "H Shen",
            "citations_all": 7979,
            "citations_recent": 2495,
            "h_index_all": 43,
            "h_index_recent": 25,
            "i10_index_all": 204,
            "i10_index_recent": 71
        }
    ],
    "abstract": "Coflow is a recently proposed networking abstraction to help improve the communication performance of data-parallel computing jobs. In multi-stage jobs, each job consists of multiple coflows and is represented by a Directed Acyclic Graph (DAG). Efficiently scheduling coflows is critical to improve the data-parallel computing performance in data centers. Compared with hand-tuned scheduling heuristics, existing work DeepWeave [1] utilizes Reinforcement Learning (RL) framework to generate highly-efficient coflow scheduling policies automatically. It employs a graph neural network (GNN) to encode the job information in a set of embedding vectors, and feeds a flat embedding vector containing the whole job information to the policy network. However, this method has poor scalability as it is unable to cope with jobs represented by DAGs of arbitrary sizes and shapes, which requires a large policy network for processing a high-dimensional embedding vector that is difficult to train. In this paper, we first utilize a directed acyclic graph neural network (DAGNN) to process the input and propose a novel Pipelined-DAGNN, which can effectively speed up the feature extraction process of the DAGNN. Next, we feed the embedding sequence composed of schedulable coflows instead of a flat embedding of all coflows to the policy network, and output a priority sequence, which makes the size of the policy network depend on only the dimension of features instead of the product of dimension and number of nodes in the job's this http URL, to improve the accuracy of the priority scheduling policy, we incorporate the Self-Attention Mechanism into a deep RL model to capture the interaction between different parts of the embedding sequence to make the output priority scores relevant. Based on this model, we then develop a coflow scheduling algorithm for online multi-stage jobs.",
    "published_date": "2021-12-21T00:00:00",
    "last_revised_date": "2021-12-21T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2112.11055.pdf",
    "primary_category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "categories": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
    ],
    "keywords": null,
    "num_pages": 12,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2024": 1
    },
    "citationCount": 1,
    "venue": {
        "name": "arXiv.org",
        "type": null,
        "ranking": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 23,
            "citationCount": 0,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 34,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 38,
            "citationCount": 125,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 14,
            "citationCount": 9,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 26,
            "citationCount": 352,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 57,
            "citationCount": 78,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 47,
            "citationCount": 24,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 52,
            "citationCount": 27,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 41,
            "citationCount": 17,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 37,
            "citationCount": 8,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 38,
            "citationCount": 234,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 138,
            "citationCount": 898,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 91,
            "citationCount": 698,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 25,
            "citationCount": 42,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 32,
            "citationCount": 172,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 41,
            "citationCount": 155122,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 43,
            "citationCount": 62,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 42,
            "citationCount": 48,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 63,
            "citationCount": 161,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 11,
            "citationCount": 37,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 40,
            "citationCount": 115,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 27,
            "citationCount": 182,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 54,
            "citationCount": 320,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 36,
            "citationCount": 116,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 41,
            "citationCount": 469,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 31,
            "citationCount": 291,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 26,
            "citationCount": 359,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 39,
            "citationCount": 4735,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 39,
            "citationCount": 665,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 17,
            "citationCount": 5302,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 23,
            "citationCount": 257,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 20,
            "citationCount": 7253,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 45,
            "citationCount": 26119,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 5,
            "citationCount": 123,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 589,
            "citationCount": 39932,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 0,
    "embedding": null
}