{
    "arxiv_id": "2501.00046",
    "title": "Numerical solutions of fixed points in two-dimensional Kuramoto-Sivashinsky equation expedited by reinforcement learning",
    "authors": [
        {
            "name": "J Jiang",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "D Wan",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "M Zhang",
            "citations_all": 2060,
            "citations_recent": 1833,
            "h_index_all": 24,
            "h_index_recent": 24,
            "i10_index_all": 45,
            "i10_index_recent": 43
        }
    ],
    "abstract": "This paper presents a combined approach to enhancing the effectiveness of Jacobian-Free Newton-Krylov (JFNK) method by deep reinforcement learning (DRL) in identifying fixed points within the 2D Kuramoto-Sivashinsky Equation (KSE). JFNK approach entails a good initial guess for improved convergence when searching for fixed points. With a properly defined reward function, we utilise DRL as a preliminary step to enhance the initial guess in the converging process. We report new results of fixed points in the 2D KSE which have not been reported in the literature. Additionally, we explored control optimization for the 2D KSE to navigate the system trajectories between known fixed points, based on parallel reinforcement learning techniques. This combined method underscores the improved JFNK approach to finding new fixed-point solutions within the context of 2D KSE, which may be instructive for other high-dimensional dynamical systems.",
    "published_date": "2024-12-27T00:00:00",
    "last_revised_date": "2024-12-27T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2501.00046.pdf",
    "primary_category": "Machine Learning (cs.LG)",
    "categories": [
        "Machine Learning (cs.LG)"
    ],
    "keywords": [
        "deep reinforcement learning",
        "Kuramotoâ€“Sivashinsky equation",
        "fixed point"
    ],
    "num_pages": 22,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {},
    "citationCount": 0,
    "venue": {
        "name": "arXiv.org",
        "type": null,
        "ranking": null
    },
    "citations": [],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}