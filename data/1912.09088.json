{
    "arxiv_id": "1912.09088",
    "title": "Resource- and Message Size-Aware Scheduling of Stream Processing at the Edge with application to Realtime Microscopy",
    "authors": [
        {
            "name": "B Blamey",
            "citations_all": 116,
            "citations_recent": 71,
            "h_index_all": 6,
            "h_index_recent": 5,
            "i10_index_all": 6,
            "i10_index_recent": 2
        },
        {
            "name": "IM Sintorn",
            "citations_all": 1959,
            "citations_recent": 1051,
            "h_index_all": 23,
            "h_index_recent": 17,
            "i10_index_all": 35,
            "i10_index_recent": 23
        },
        {
            "name": "A Hellander",
            "citations_all": 2757,
            "citations_recent": 1389,
            "h_index_all": 25,
            "h_index_recent": 20,
            "i10_index_all": 50,
            "i10_index_recent": 39
        },
        {
            "name": "S Toor",
            "citations_all": 3347,
            "citations_recent": 902,
            "h_index_all": 16,
            "h_index_recent": 13,
            "i10_index_all": 24,
            "i10_index_recent": 17
        }
    ],
    "abstract": "Whilst computational resources at the cloud edge can be leveraged to improve latency and reduce the costs of cloud services for a wide variety mobile, web, and IoT applications; such resources are naturally constrained. For distributed stream processing applications, there are clear advantages to offloading some processing work to the cloud edge. Many state of the art stream processing applications such as Flink and Spark Streaming, being designed to run exclusively in the cloud, are a poor fit for such hybrid edge/cloud deployment settings, not least because their schedulers take limited consideration of the heterogeneous hardware in such deployments. In particular, their schedulers broadly assume a homogeneous network topology (aside from data locality consideration in, e.g., HDFS/Spark). Specialized stream processing frameworks intended for such hybrid deployment scenarios, especially IoT applications, allow developers to manually allocate specific operators in the pipeline to nodes at the cloud edge. In this paper, we investigate scheduling stream processing in hybrid cloud/edge deployment settings with sensitivity to CPU costs and message size, with the aim of maximizing throughput with respect to limited edge resources. We demonstrate real-time edge processing of a stream of electron microscopy images, and measure a consistent reduction in end-to-end latency under our approach versus a resource-agnostic baseline scheduler, under benchmarking.",
    "published_date": "2019-12-19T00:00:00",
    "last_revised_date": "2019-12-19T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/1912.09088.pdf",
    "primary_category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "categories": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "keywords": null,
    "num_pages": 8,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2020": 1,
        "2021": 3,
        "2024": 1,
        "2025": 1
    },
    "citationCount": 6,
    "venue": {
        "name": "arXiv.org",
        "type": null,
        "ranking": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 26,
            "citationCount": 3,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 39,
            "citationCount": 3,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 14,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 23,
            "citationCount": 21,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 24,
            "citationCount": 30,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 45,
            "citationCount": 42,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 35,
            "citationCount": 40,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 23,
            "citationCount": 15,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 12,
            "citationCount": 34,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 44,
            "citationCount": 128,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 15,
            "citationCount": 422,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 10,
            "citationCount": 1022,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 7,
            "citationCount": 58,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 22,
            "citationCount": 111,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 29,
            "citationCount": 27,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 22,
            "citationCount": 7,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 31,
            "citationCount": 1317,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 0,
    "embedding": null
}