{
    "arxiv_id": "2501.10379",
    "title": "What Information Should Be Shared with Whom \"Before and During Training\"?",
    "authors": [
        {
            "name": "H Belfield",
            "citations_all": 3322,
            "citations_recent": 2850,
            "h_index_all": 11,
            "h_index_recent": 11,
            "i10_index_all": 12,
            "i10_index_recent": 12
        }
    ],
    "abstract": "In the Frontier AI Safety Commitments, sixteen companies committed to \"Assess the risks posed by their frontier models or systems across the AI lifecycle, including [...] as appropriate, before and during training\" (I) and to \"Provide public transparency on the implementation of the above (I-VI), except insofar as doing so would increase risk or divulge sensitive commercial information to a degree disproportionate to the societal benefit. They should still share more detailed information which cannot be shared publicly with trusted actors, including their respective home governments or appointed body, as appropriate\" (VII). This short paper considers what information should be shared with whom before training begins. What information should be shared publicly and what only with trusted actors such as home governments? Sharing such information before a frontier training run can build shared awareness and preparedness, can improve risk assessment and management, and can contribute to greater predictability and accountability. Companies could share certain information before a training run including:\nExpected dates of beginning and end of training;\nExpected compute used (in FLOP);\nDescription of the pre-training dataset(s);\nExpected capability level of the frontier model or system, including an assessment of potential risks and whether this capability will approach any risk threshold;\nHow the company will monitor progress, capabilities and risks during training;\nLocation, ownership, primary energy source of the large-scale computing cluster(s);\nPhysical, personnel and cybersecurity steps taken; and\nWhich internal and external groups have been tasked to carry out evaluations and red-teaming and what level of resources, support and time they have available to do so.",
    "published_date": "2024-12-17T00:00:00",
    "last_revised_date": "2024-12-17T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2501.10379.pdf",
    "primary_category": "Computers and Society (cs.CY)",
    "categories": [
        "Computers and Society (cs.CY)"
    ],
    "keywords": null,
    "num_pages": 7,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {},
    "citationCount": 0,
    "venue": {
        "name": "arXiv.org",
        "type": null,
        "ranking": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 39,
            "citationCount": 0,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}