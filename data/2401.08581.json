{
    "arxiv_id": "2401.08581",
    "title": "Temporal Embeddings: Scalable Self-Supervised Temporal Representation Learning from Spatiotemporal Data for Multimodal Computer Vision",
    "authors": [
        {
            "name": "Y Cao",
            "citations_all": 405,
            "citations_recent": 167,
            "h_index_all": 10,
            "h_index_recent": 8,
            "i10_index_all": 11,
            "i10_index_recent": 5
        },
        {
            "name": "S Ganguli",
            "citations_all": 355,
            "citations_recent": 296,
            "h_index_all": 9,
            "h_index_recent": 8,
            "i10_index_all": 9,
            "i10_index_recent": 7
        },
        {
            "name": "V Pandey",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        }
    ],
    "abstract": "There exists a correlation between geospatial activity temporal patterns and type of land use. A novel self-supervised approach is proposed to stratify landscape based on mobility activity time series. First, the time series signal is transformed to the frequency domain and then compressed into task-agnostic temporal embeddings by a contractive autoencoder, which preserves cyclic temporal patterns observed in time series. The pixel-wise embeddings are converted to image-like channels that can be used for task-based, multimodal modeling of downstream geospatial tasks using deep semantic segmentation. Experiments show that temporal embeddings are semantically meaningful representations of time series data and are effective across different tasks such as classifying residential area and commercial areas. Temporal embeddings transform sequential, spatiotemporal motion trajectory data into semantically meaningful image-like tensor representations that can be combined (multimodal fusion) with other data modalities that are or can be transformed into image-like tensor representations (for e.g., RBG imagery, graph embeddings of road networks, passively collected imagery like SAR, etc.) to facilitate multimodal learning in geospatial computer vision. Multimodal computer vision is critical for training machine learning models for geospatial feature detection to keep a geospatial mapping service up-to-date in real-time and can significantly improve user experience and above all, user safety.",
    "published_date": "2023-10-16T00:00:00",
    "last_revised_date": "2023-10-16T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2401.08581.pdf",
    "primary_category": "Computer Vision and Pattern Recognition (cs.CV)",
    "categories": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
    ],
    "keywords": null,
    "num_pages": 3,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2024": 1,
        "2025": 1
    },
    "citationCount": 2,
    "venue": {
        "name": "arXiv.org",
        "type": null,
        "ranking": null
    },
    "citations": [],
    "referenceCount": 8,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 88,
            "citationCount": 3,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 8,
            "citationCount": 2,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 56,
            "citationCount": 5,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 34,
            "citationCount": 23,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 29,
            "citationCount": 15,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 2,
            "citationCount": 64934,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 0,
    "embedding": null
}