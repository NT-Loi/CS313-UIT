{
    "arxiv_id": "2412.18955",
    "title": "Leave-One-EquiVariant: Alleviating invariance-related information loss in contrastive music representations",
    "authors": [
        {
            "name": "J Guinot",
            "citations_all": 49,
            "citations_recent": 49,
            "h_index_all": 3,
            "h_index_recent": 3,
            "i10_index_all": 1,
            "i10_index_recent": 1
        },
        {
            "name": "E Quinton",
            "citations_all": 414,
            "citations_recent": 382,
            "h_index_all": 8,
            "h_index_recent": 7,
            "i10_index_all": 8,
            "i10_index_recent": 7
        },
        {
            "name": "G Fazekas",
            "citations_all": 5908,
            "citations_recent": 4018,
            "h_index_all": 37,
            "h_index_recent": 30,
            "i10_index_all": 111,
            "i10_index_recent": 79
        }
    ],
    "abstract": "Contrastive learning has proven effective in self-supervised musical representation learning, particularly for Music Information Retrieval (MIR) tasks. However, reliance on augmentation chains for contrastive view generation and the resulting learnt invariances pose challenges when different downstream tasks require sensitivity to certain musical attributes. To address this, we propose the Leave One EquiVariant (LOEV) framework, which introduces a flexible, task-adaptive approach compared to previous work by selectively preserving information about specific augmentations, allowing the model to maintain task-relevant equivariances. We demonstrate that LOEV alleviates information loss related to learned invariances, improving performance on augmentation related tasks and retrieval without sacrificing general representation quality. Furthermore, we introduce a variant of LOEV, LOEV++, which builds a disentangled latent space by design in a self-supervised manner, and enables targeted retrieval based on augmentation related attributes.",
    "published_date": "2024-12-25T00:00:00",
    "last_revised_date": "2024-12-25T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2412.18955.pdf",
    "primary_category": "Sound (cs.SD)",
    "categories": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
    ],
    "keywords": null,
    "num_pages": 7,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {},
    "citationCount": 4,
    "venue": {
        "name": "arXiv.org",
        "type": null,
        "ranking": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 28,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 34,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 40,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 65,
            "citationCount": 0,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}