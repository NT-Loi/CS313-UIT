{
    "arxiv_id": "2412.18797",
    "title": "DRDM: A Disentangled Representations Diffusion Model for Synthesizing Realistic Person Images",
    "authors": [
        {
            "name": "E Huang",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "Y Zhang",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "F Huang",
            "citations_all": 1476,
            "citations_recent": 1174,
            "h_index_all": 19,
            "h_index_recent": 16,
            "i10_index_all": 32,
            "i10_index_recent": 24
        },
        {
            "name": "G Zhang",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "Y Liu",
            "citations_all": 1554,
            "citations_recent": 1533,
            "h_index_all": 19,
            "h_index_recent": 19,
            "i10_index_all": 23,
            "i10_index_recent": 23
        }
    ],
    "abstract": "Person image synthesis with controllable body poses and appearances is an essential task owing to the practical needs in the context of virtual try-on, image editing and video production. However, existing methods face significant challenges with details missing, limbs distortion and the garment style deviation. To address these issues, we propose a Disentangled Representations Diffusion Model (DRDM) to generate photo-realistic images from source portraits in specific desired poses and appearances. First, a pose encoder is responsible for encoding pose features into a high-dimensional space to guide the generation of person images. Second, a body-part subspace decoupling block (BSDB) disentangles features from the different body parts of a source figure and feeds them to the various layers of the noise prediction block, thereby supplying the network with rich disentangled features for generating a realistic target image. Moreover, during inference, we develop a parsing map-based disentangled classifier-free guided sampling method, which amplifies the conditional signals of texture and pose. Extensive experimental results on the Deepfashion dataset demonstrate the effectiveness of our approach in achieving pose transfer and appearance control.",
    "published_date": "2024-12-25T00:00:00",
    "last_revised_date": "2024-12-25T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2412.18797.pdf",
    "primary_category": "Computer Vision and Pattern Recognition (cs.CV)",
    "categories": [
        "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "keywords": null,
    "num_pages": 5,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {},
    "citationCount": 1,
    "venue": {
        "name": "arXiv.org",
        "type": null,
        "ranking": null
    },
    "citations": [],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}