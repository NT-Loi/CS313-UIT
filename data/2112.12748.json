{
    "arxiv_id": "2112.12748",
    "title": "Assessing the Impact of Attention and Self-Attention Mechanisms on the Classification of Skin Lesions",
    "authors": [
        {
            "name": "R Pedro",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "AL Oliveira",
            "citations_all": 12607,
            "citations_recent": 5010,
            "h_index_all": 43,
            "h_index_recent": 23,
            "i10_index_all": 123,
            "i10_index_recent": 55
        }
    ],
    "abstract": "Attention mechanisms have raised significant interest in the research community, since they promise significant improvements in the performance of neural network architectures. However, in any specific problem, we still lack a principled way to choose specific mechanisms and hyper-parameters that lead to guaranteed improvements. More recently, self-attention has been proposed and widely used in transformer-like architectures, leading to significant breakthroughs in some applications. In this work we focus on two forms of attention mechanisms: attention modules and self-attention. Attention modules are used to reweight the features of each layer input tensor. Different modules have different ways to perform this reweighting in fully connected or convolutional layers. The attention models studied are completely modular and in this work they will be used with the popular ResNet architecture. Self-Attention, originally proposed in the area of Natural Language Processing makes it possible to relate all the items in an input sequence. Self-Attention is becoming increasingly popular in Computer Vision, where it is sometimes combined with convolutional layers, although some recent architectures do away entirely with convolutions. In this work, we study and perform an objective comparison of a number of different attention mechanisms in a specific computer vision task, the classification of samples in the widely used Skin Cancer MNIST dataset. The results show that attention modules do sometimes improve the performance of convolutional neural network architectures, but also that this improvement, although noticeable and statistically significant, is not consistent in different settings. The results obtained with self-attention mechanisms, on the other hand, show consistent and significant improvements, leading to the best results even in architectures with a reduced number of parameters.",
    "published_date": "2021-12-23T00:00:00",
    "last_revised_date": "2021-12-23T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2112.12748.pdf",
    "primary_category": "Computer Vision and Pattern Recognition (cs.CV)",
    "categories": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
    ],
    "keywords": null,
    "num_pages": 9,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2022": 4,
        "2023": 3,
        "2024": 8,
        "2025": 8
    },
    "citationCount": 23,
    "venue": {
        "name": "IEEE International Joint Conference on Neural Network",
        "type": "conference",
        "ranking": "B"
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 48,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 18,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 9,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 39,
            "citationCount": 4,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 36,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 41,
            "citationCount": 6,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 130,
            "citationCount": 21,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 14,
            "citationCount": 2,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 31,
            "citationCount": 3,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 35,
            "citationCount": 3,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 38,
            "citationCount": 2,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 19,
            "citationCount": 1,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 41,
            "citationCount": 2,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 52,
            "citationCount": 2,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 148,
            "citationCount": 100,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 48,
            "citationCount": 9,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 23,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 57,
            "citationCount": 899,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 66,
            "citationCount": 7466,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 10,
            "citationCount": 105,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 65,
            "citationCount": 47432,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 40,
            "citationCount": 680,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 53,
            "citationCount": 14485,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 42,
            "citationCount": 4437,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 71,
            "citationCount": 1254,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 63,
            "citationCount": 1047,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 11,
            "citationCount": 1329,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 51,
            "citationCount": 353,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 44,
            "citationCount": 2785,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 43,
            "citationCount": 18071,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 35,
            "citationCount": 2953,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 37,
            "citationCount": 447,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 85,
            "citationCount": 28201,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 41,
            "citationCount": 144959,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 72,
            "citationCount": 21854,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 42,
            "citationCount": 4549,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 53,
            "citationCount": 203603,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 26,
            "citationCount": 3732,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 27,
            "citationCount": 66569,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 1,
    "embedding": null
}