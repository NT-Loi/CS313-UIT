{
    "arxiv_id": "2412.20916",
    "title": "Low-Light Image Enhancement via Generative Perceptual Priors",
    "authors": [
        {
            "name": "H Zhou",
            "citations_all": 533,
            "citations_recent": 516,
            "h_index_all": 14,
            "h_index_recent": 14,
            "i10_index_all": 16,
            "i10_index_recent": 16
        },
        {
            "name": "W Dong",
            "citations_all": 1406,
            "citations_recent": 1405,
            "h_index_all": 24,
            "h_index_recent": 24,
            "i10_index_all": 33,
            "i10_index_recent": 33
        },
        {
            "name": "X Liu",
            "citations_all": 4926,
            "citations_recent": 4912,
            "h_index_all": 31,
            "h_index_recent": 31,
            "i10_index_all": 74,
            "i10_index_recent": 74
        },
        {
            "name": "Y Zhang",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "G Zhai",
            "citations_all": 27022,
            "citations_recent": 21913,
            "h_index_all": 79,
            "h_index_recent": 73,
            "i10_index_all": 398,
            "i10_index_recent": 354
        },
        {
            "name": "J Chen",
            "citations_all": 7251,
            "citations_recent": 5534,
            "h_index_all": 41,
            "h_index_recent": 33,
            "i10_index_all": 109,
            "i10_index_recent": 77
        }
    ],
    "abstract": "Although significant progress has been made in enhancing visibility, retrieving texture details, and mitigating noise in Low-Light (LL) images, the challenge persists in applying current Low-Light Image Enhancement (LLIE) methods to real-world scenarios, primarily due to the diverse illumination conditions encountered. Furthermore, the quest for generating enhancements that are visually realistic and attractive remains an underexplored realm. In response to these challenges, we introduce a novel \\textbf{LLIE} framework with the guidance of \\textbf{G}enerative \\textbf{P}erceptual \\textbf{P}riors (\\textbf{GPP-LLIE}) derived from vision-language models (VLMs). Specifically, we first propose a pipeline that guides VLMs to assess multiple visual attributes of the LL image and quantify the assessment to output the global and local perceptual priors. Subsequently, to incorporate these generative perceptual priors to benefit LLIE, we introduce a transformer-based backbone in the diffusion process, and develop a new layer normalization (\\textit{\\textbf{GPP-LN}}) and an attention mechanism (\\textit{\\textbf{LPP-Attn}}) guided by global and local perceptual priors. Extensive experiments demonstrate that our model outperforms current SOTA methods on paired LL datasets and exhibits superior generalization on real-world data. The code is released at \\url{this https URL}.",
    "published_date": "2024-12-30T00:00:00",
    "last_revised_date": "2024-12-30T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2412.20916.pdf",
    "primary_category": "Computer Vision and Pattern Recognition (cs.CV)",
    "categories": [
        "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "keywords": null,
    "num_pages": 9,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {},
    "citationCount": 11,
    "venue": {
        "name": "arXiv.org",
        "type": null,
        "ranking": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 62,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 24,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 51,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 57,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 56,
            "citationCount": 4,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 30,
            "citationCount": 0,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 1,
    "embedding": null
}