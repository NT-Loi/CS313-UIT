{
    "arxiv_id": "2101.00073",
    "title": "A Multi-modal Deep Learning Model for Video Thumbnail Selection",
    "authors": [
        {
            "name": "Z Yu",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "N Shi",
            "citations_all": 8,
            "citations_recent": 8,
            "h_index_all": 1,
            "h_index_recent": 1,
            "i10_index_all": 0,
            "i10_index_recent": 0
        }
    ],
    "abstract": "Thumbnail is the face of online videos. The explosive growth of videos both in number and variety underpins the importance of a good thumbnail because it saves potential viewers time to choose videos and even entice them to click on them. A good thumbnail should be a frame that best represents the content of a video while at the same time capturing viewers' attention. However, the techniques and models in the past only focus on frames within a video, and we believe such narrowed focus leave out much useful information that are part of a video. In this paper, we expand the definition of content to include title, description, and audio of a video and utilize information provided by these modalities in our selection model. Specifically, our model will first sample frames uniformly in time and return the top 1,000 frames in this subset with the highest aesthetic scores by a Double-column Convolutional Neural Network, to avoid the computational burden of processing all frames in downstream task. Then, the model incorporates frame features extracted from VGG16, text features from ELECTRA, and audio features from TRILL. These models were selected because of their results on popular datasets as well as their competitive performances. After feature extraction, the time-series features, frames and audio, will be fed into Transformer encoder layers to return a vector representing their corresponding modality. Each of the four features (frames, title, description, audios) will pass through a context gating layer before concatenation. Finally, our model will generate a vector in the latent space and select the frame that is most similar to this vector in the latent space. To the best of our knowledge, we are the first to propose a multi-modal deep learning model to select video thumbnail, which beats the result from the previous State-of-The-Art models.",
    "published_date": "2020-12-31T00:00:00",
    "last_revised_date": "2020-12-31T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2101.00073.pdf",
    "primary_category": "Computer Vision and Pattern Recognition (cs.CV)",
    "categories": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
    ],
    "keywords": null,
    "num_pages": 9,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2021": 3,
        "2022": 2,
        "2023": 1,
        "2024": 1,
        "2025": 1
    },
    "citationCount": 8,
    "venue": {
        "name": "arXiv.org",
        "type": null,
        "ranking": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 15,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 27,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 33,
            "citationCount": 10,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 17,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 35,
            "citationCount": 3611,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 54,
            "citationCount": 163,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 16,
            "citationCount": 14,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 56,
            "citationCount": 330,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 41,
            "citationCount": 144903,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 47,
            "citationCount": 117,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 32,
            "citationCount": 207,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 30,
            "citationCount": 243,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 43,
            "citationCount": 103185,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 23,
            "citationCount": 971,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 12,
            "citationCount": 28,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 0,
            "citationCount": 41727,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 63,
            "citationCount": 100609,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 25,
            "citationCount": 7,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 0,
            "citationCount": 168635,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 0,
    "embedding": null
}