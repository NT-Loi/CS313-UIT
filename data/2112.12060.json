{
    "arxiv_id": "2112.12060",
    "title": "Deep Models for Visual Sentiment Analysis of Disaster-related Multimedia Content",
    "authors": [
        {
            "name": "K Ahmad",
            "citations_all": 73,
            "citations_recent": 73,
            "h_index_all": 6,
            "h_index_recent": 6,
            "i10_index_all": 3,
            "i10_index_recent": 3
        },
        {
            "name": "MA Ayub",
            "citations_all": 58,
            "citations_recent": 58,
            "h_index_all": 6,
            "h_index_recent": 6,
            "i10_index_all": 1,
            "i10_index_recent": 1
        },
        {
            "name": "K Ahmad",
            "citations_all": 3648,
            "citations_recent": 3459,
            "h_index_all": 27,
            "h_index_recent": 27,
            "i10_index_all": 47,
            "i10_index_recent": 44
        },
        {
            "name": "A Al-Fuqaha",
            "citations_all": 31265,
            "citations_recent": 24639,
            "h_index_all": 55,
            "h_index_recent": 52,
            "i10_index_all": 160,
            "i10_index_recent": 129
        },
        {
            "name": "N Ahmad",
            "citations_all": 2655,
            "citations_recent": 2112,
            "h_index_all": 17,
            "h_index_recent": 14,
            "i10_index_all": 36,
            "i10_index_recent": 25
        }
    ],
    "abstract": "This paper presents a solutions for the MediaEval 2021 task namely \"Visual Sentiment Analysis: A Natural Disaster Use-case\". The task aims to extract and classify sentiments perceived by viewers and the emotional message conveyed by natural disaster-related images shared on social media. The task is composed of three sub-tasks including, one single label multi-class image classification task, and, two multi-label multi-class image classification tasks, with different sets of labels. In our proposed solutions, we rely mainly on two different state-of-the-art models namely, Inception-v3 and VggNet-19, pre-trained on ImageNet, which are fine-tuned for each of the three task using different strategies. Overall encouraging results are obtained on all the three tasks. On the single-label classification task (i.e. Task 1), we obtained the weighted average F1-scores of 0.540 and 0.526 for the Inception-v3 and VggNet-19 based solutions, respectively. On the multi-label classification i.e., Task 2 and Task 3, the weighted F1-score of our Inception-v3 based solutions was 0.572 and 0.516, respectively. Similarly, the weighted F1-score of our VggNet-19 based solution on Task 2 and Task 3 was 0.584 and 0.495, respectively.",
    "published_date": "2021-11-30T00:00:00",
    "last_revised_date": "2021-11-30T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2112.12060.pdf",
    "primary_category": "Computer Vision and Pattern Recognition (cs.CV)",
    "categories": [
        "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "keywords": null,
    "num_pages": 2,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {},
    "citationCount": 0,
    "venue": {
        "name": "MediaEval Benchmarking Initiative for Multimedia Evaluation",
        "type": "conference"
    },
    "citations": [],
    "referenceCount": 11,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 12,
            "citationCount": 7,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 44,
            "citationCount": 57,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 27,
            "citationCount": 10,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 24,
            "citationCount": 23,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 152,
            "citationCount": 119,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 48,
            "citationCount": 4318,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 28,
            "citationCount": 28,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 27,
            "citationCount": 66567,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 84,
            "citationCount": 160,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 15,
            "citationCount": 14,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 142,
            "citationCount": 208,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 0,
    "embedding": null
}