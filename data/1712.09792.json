{
    "arxiv_id": "1712.09792",
    "title": "Siamese LSTM based Fiber Structural Similarity Network (FS2Net) for Rotation Invariant Brain Tractography Segmentation",
    "authors": [
        {
            "name": "SM Patil",
            "citations_all": 174,
            "citations_recent": 155,
            "h_index_all": 8,
            "h_index_recent": 8,
            "i10_index_all": 6,
            "i10_index_recent": 6
        },
        {
            "name": "A Nigam",
            "citations_all": 2027,
            "citations_recent": 1434,
            "h_index_all": 24,
            "h_index_recent": 19,
            "i10_index_all": 59,
            "i10_index_recent": 38
        },
        {
            "name": "A Bhavsar",
            "citations_all": 1815,
            "citations_recent": 1387,
            "h_index_all": 20,
            "h_index_recent": 18,
            "i10_index_all": 52,
            "i10_index_recent": 40
        },
        {
            "name": "C Chattopadhyay",
            "citations_all": 802,
            "citations_recent": 682,
            "h_index_all": 14,
            "h_index_recent": 14,
            "i10_index_all": 22,
            "i10_index_recent": 19
        }
    ],
    "abstract": "In this paper, we propose a novel deep learning architecture combining stacked Bi-directional LSTM and LSTMs with the Siamese network architecture for segmentation of brain fibers, obtained from tractography data, into anatomically meaningful clusters. The proposed network learns the structural difference between fibers of different classes, which enables it to classify fibers with high accuracy. Importantly, capturing such deep inter and intra class structural relationship also ensures that the segmentation is robust to relative rotation among test and training data, hence can be used with unregistered data. Our extensive experimentation over order of hundred-thousands of fibers show that the proposed model achieves state-of-the-art results, even in cases of large relative rotations between test and training data.",
    "published_date": "2017-12-28T00:00:00",
    "last_revised_date": "2017-12-28T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/1712.09792.pdf",
    "primary_category": "Computer Vision and Pattern Recognition (cs.CV)",
    "categories": [
        "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "keywords": null,
    "num_pages": 5,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2019": 1,
        "2021": 4,
        "2023": 1,
        "2024": 1,
        "2025": 1
    },
    "citationCount": 8,
    "venue": {
        "name": "arXiv.org",
        "type": null,
        "ranking": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 71,
            "citationCount": 69,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 40,
            "citationCount": 3,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 93,
            "citationCount": 38,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 77,
            "citationCount": 1,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 81,
            "citationCount": 68,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 127,
            "citationCount": 522,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 77,
            "citationCount": 10,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 12,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 10,
            "citationCount": 11,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 15,
            "citationCount": 60,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 6,
            "citationCount": 6,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 30,
            "citationCount": 356,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 14,
            "citationCount": 5,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 41,
            "citationCount": 63,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 55,
            "citationCount": 382,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 21,
            "citationCount": 92,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 69,
            "citationCount": 1658,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 48,
            "citationCount": 95318,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 31,
            "citationCount": 4332,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 93,
            "citationCount": 264,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 0,
    "embedding": null
}