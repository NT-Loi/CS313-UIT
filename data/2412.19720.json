{
    "arxiv_id": "2412.19720",
    "title": "Sharpening Neural Implicit Functions with Frequency Consolidation Priors",
    "authors": [
        {
            "name": "C Chen",
            "citations_all": 314,
            "citations_recent": 314,
            "h_index_all": 8,
            "h_index_recent": 8,
            "i10_index_all": 7,
            "i10_index_recent": 7
        },
        {
            "name": "YS Liu",
            "citations_all": 7824,
            "citations_recent": 6676,
            "h_index_all": 46,
            "h_index_recent": 42,
            "i10_index_all": 106,
            "i10_index_recent": 91
        },
        {
            "name": "Z Han",
            "citations_all": 6698,
            "citations_recent": 6254,
            "h_index_all": 43,
            "h_index_recent": 40,
            "i10_index_all": 81,
            "i10_index_recent": 80
        }
    ],
    "abstract": "Signed Distance Functions (SDFs) are vital implicit representations to represent high fidelity 3D surfaces. Current methods mainly leverage a neural network to learn an SDF from various supervisions including signed distances, 3D point clouds, or multi-view images. However, due to various reasons including the bias of neural network on low frequency content, 3D unaware sampling, sparsity in point clouds, or low resolutions of images, neural implicit representations still struggle to represent geometries with high frequency components like sharp structures, especially for the ones learned from images or point clouds. To overcome this challenge, we introduce a method to sharpen a low frequency SDF observation by recovering its high frequency components, pursuing a sharper and more complete surface. Our key idea is to learn a mapping from a low frequency observation to a full frequency coverage in a data-driven manner, leading to a prior knowledge of shape consolidation in the frequency domain, dubbed frequency consolidation priors. To better generalize a learned prior to unseen shapes, we introduce to represent frequency components as embeddings and disentangle the embedding of the low frequency component from the embedding of the full frequency component. This disentanglement allows the prior to generalize on an unseen low frequency observation by simply recovering its full frequency embedding through a test-time self-reconstruction. Our evaluations under widely used benchmarks or real scenes show that our method can recover high frequency component and produce more accurate surfaces than the latest methods. The code, data, and pre-trained models are available at \\url{this https URL}.",
    "published_date": "2024-12-27T00:00:00",
    "last_revised_date": "2024-12-27T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2412.19720.pdf",
    "primary_category": "Computer Vision and Pattern Recognition (cs.CV)",
    "categories": [
        "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "keywords": null,
    "num_pages": 9,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {},
    "citationCount": 1,
    "venue": {
        "name": "arXiv.org",
        "type": null,
        "ranking": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 97,
            "citationCount": 8,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 73,
            "citationCount": 0,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}