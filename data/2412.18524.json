{
    "arxiv_id": "2412.18524",
    "title": "HTR-JAND: Handwritten Text Recognition with Joint Attention Network and Knowledge Distillation",
    "authors": [
        {
            "name": "M Hamdan",
            "citations_all": 68,
            "citations_recent": 66,
            "h_index_all": 4,
            "h_index_recent": 4,
            "i10_index_all": 2,
            "i10_index_recent": 2
        },
        {
            "name": "A Rahiche",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "M Cheriet",
            "citations_all": 16007,
            "citations_recent": 7140,
            "h_index_all": 61,
            "h_index_recent": 43,
            "i10_index_all": 322,
            "i10_index_recent": 176
        }
    ],
    "abstract": "Despite significant advances in deep learning, current Handwritten Text Recognition (HTR) systems struggle with the inherent complexity of historical documents, including diverse writing styles, degraded text quality, and computational efficiency requirements across multiple languages and time periods. This paper introduces HTR-JAND (HTR-JAND: Handwritten Text Recognition with Joint Attention Network and Knowledge Distillation), an efficient HTR framework that combines advanced feature extraction with knowledge distillation. Our architecture incorporates three key components: (1) a CNN architecture integrating FullGatedConv2d layers with Squeeze-and-Excitation blocks for adaptive feature extraction, (2) a Combined Attention mechanism fusing Multi-Head Self-Attention with Proxima Attention for robust sequence modeling, and (3) a Knowledge Distillation framework enabling efficient model compression while preserving accuracy through curriculum-based training. The HTR-JAND framework implements a multi-stage training approach combining curriculum learning, synthetic data generation, and multi-task learning for cross-dataset knowledge transfer. We enhance recognition accuracy through context-aware T5 post-processing, particularly effective for historical documents. Comprehensive evaluations demonstrate HTR-JAND's effectiveness, achieving state-of-the-art Character Error Rates (CER) of 1.23\\%, 1.02\\%, and 2.02\\% on IAM, RIMES, and Bentham datasets respectively. Our Student model achieves a 48\\% parameter reduction (0.75M versus 1.5M parameters) while maintaining competitive performance through efficient knowledge transfer. Source code and pre-trained models are available at \\href{this https URL}{Github}.",
    "published_date": "2024-12-24T00:00:00",
    "last_revised_date": "2024-12-24T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2412.18524.pdf",
    "primary_category": "Computer Vision and Pattern Recognition (cs.CV)",
    "categories": [
        "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "keywords": null,
    "num_pages": 13,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2025": 2
    },
    "citationCount": 2,
    "venue": {
        "name": "arXiv.org",
        "type": null,
        "ranking": null
    },
    "citations": [],
    "referenceCount": 0,
    "references": [],
    "influentialCitationCount": 0,
    "embedding": null
}