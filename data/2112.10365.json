{
    "arxiv_id": "2112.10365",
    "title": "DMS-GCN: Dynamic Mutiscale Spatiotemporal Graph Convolutional Networks for Human Motion Prediction",
    "authors": [
        {
            "name": "Z Yan",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "DH Zhai",
            "citations_all": 2484,
            "citations_recent": 1909,
            "h_index_all": 26,
            "h_index_recent": 25,
            "i10_index_all": 51,
            "i10_index_recent": 49
        },
        {
            "name": "Y Xia",
            "citations_all": 39437,
            "citations_recent": 24661,
            "h_index_all": 99,
            "h_index_recent": 74,
            "i10_index_all": 622,
            "i10_index_recent": 516
        }
    ],
    "abstract": "Human motion prediction is an important and challenging task in many computer vision application domains. Recent work concentrates on utilizing the timing processing ability of recurrent neural networks (RNNs) to achieve smooth and reliable results in short-term prediction. However, as evidenced by previous work, RNNs suffer from errors accumulation, leading to unreliable results. In this paper, we propose a simple feed-forward deep neural network for motion prediction, which takes into account temporal smoothness and spatial dependencies between human body joints. We design a Multi-scale Spatio-temporal graph convolutional networks (GCNs) to implicitly establish the Spatio-temporal dependence in the process of human movement, where different scales fused dynamically during training. The entire model is suitable for all actions and follows a framework of encoder-decoder. The encoder consists of temporal GCNs to capture motion features between frames and semi-autonomous learned spatial GCNs to extract spatial structure among joint trajectories. The decoder uses temporal convolution networks (TCNs) to maintain its extensive ability. Extensive experiments show that our approach outperforms SOTA methods on the datasets of Human3.6M and CMU Mocap while only requiring much lesser parameters. Code will be available at this https URL.",
    "published_date": "2021-12-20T00:00:00",
    "last_revised_date": "2021-12-20T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2112.10365.pdf",
    "primary_category": "Computer Vision and Pattern Recognition (cs.CV)",
    "categories": [
        "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "keywords": null,
    "num_pages": 7,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2022": 2,
        "2023": 4,
        "2024": 1,
        "2025": 3
    },
    "citationCount": 10,
    "venue": {
        "name": "arXiv.org",
        "type": null,
        "ranking": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 59,
            "citationCount": 7,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 43,
            "citationCount": 10,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 77,
            "citationCount": 51,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 101,
            "citationCount": 82,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 61,
            "citationCount": 1,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 21,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 54,
            "citationCount": 161,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 54,
            "citationCount": 219,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 32,
            "citationCount": 146,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 48,
            "citationCount": 325,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 35,
            "citationCount": 195,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 26,
            "citationCount": 473,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 42,
            "citationCount": 41,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 35,
            "citationCount": 124,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 107,
            "citationCount": 183,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 23,
            "citationCount": 344,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 32,
            "citationCount": 4450,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 54,
            "citationCount": 969,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 66,
            "citationCount": 1123,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 53,
            "citationCount": 974,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 20,
            "citationCount": 13223,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 68,
            "citationCount": 3430,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 35,
            "citationCount": 1128,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 27,
            "citationCount": 48,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 64,
            "citationCount": 134,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 33,
            "citationCount": 162,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 48,
            "citationCount": 178,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 0,
    "embedding": null
}