{
    "arxiv_id": "2212.11346",
    "title": "Deep Unfolded Tensor Robust PCA with Self-supervised Learning",
    "authors": [
        {
            "name": "H Dong",
            "citations_all": 174,
            "citations_recent": 174,
            "h_index_all": 6,
            "h_index_recent": 6,
            "i10_index_all": 4,
            "i10_index_recent": 4
        },
        {
            "name": "M Shah",
            "citations_all": 1368,
            "citations_recent": 825,
            "h_index_all": 10,
            "h_index_recent": 9,
            "i10_index_all": 10,
            "i10_index_recent": 8
        },
        {
            "name": "S Donegan",
            "citations_all": 631,
            "citations_recent": 537,
            "h_index_all": 14,
            "h_index_recent": 13,
            "i10_index_all": 17,
            "i10_index_recent": 16
        },
        {
            "name": "Y Chi",
            "citations_all": 10700,
            "citations_recent": 8207,
            "h_index_all": 50,
            "h_index_recent": 48,
            "i10_index_all": 107,
            "i10_index_recent": 98
        }
    ],
    "abstract": "Tensor robust principal component analysis (RPCA), which seeks to separate a low-rank tensor from its sparse corruptions, has been crucial in data science and machine learning where tensor structures are becoming more prevalent. While powerful, existing tensor RPCA algorithms can be difficult to use in practice, as their performance can be sensitive to the choice of additional hyperparameters, which are not straightforward to tune. In this paper, we describe a fast and simple self-supervised model for tensor RPCA using deep unfolding by only learning four hyperparameters. Despite its simplicity, our model expunges the need for ground truth labels while maintaining competitive or even greater performance compared to supervised deep unfolding. Furthermore, our model is capable of operating in extreme data-starved scenarios. We demonstrate these claims on a mix of synthetic data and real-world tasks, comparing performance against previously studied supervised deep unfolding methods and Bayesian optimization baselines.",
    "published_date": "2022-12-21T00:00:00",
    "last_revised_date": "2022-12-21T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2212.11346.pdf",
    "primary_category": "Machine Learning (stat.ML)",
    "categories": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
    ],
    "keywords": null,
    "num_pages": 9,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2023": 3,
        "2025": 4
    },
    "citationCount": 7,
    "venue": {
        "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
        "type": "conference",
        "ranking": "B"
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 64,
            "citationCount": 2,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 31,
            "citationCount": 1,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 76,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 37,
            "citationCount": 1,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 49,
            "citationCount": 3,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 49,
            "citationCount": 14,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 24,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 49,
            "citationCount": 14,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 34,
            "citationCount": 4,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 49,
            "citationCount": 52,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 43,
            "citationCount": 17,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 23,
            "citationCount": 33,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 86,
            "citationCount": 37,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 36,
            "citationCount": 56,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 27,
            "citationCount": 15,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 61,
            "citationCount": 127,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 59,
            "citationCount": 10,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 35,
            "citationCount": 6958,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 30,
            "citationCount": 17,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 74,
            "citationCount": 88,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 46,
            "citationCount": 14,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 65,
            "citationCount": 198,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 43,
            "citationCount": 814,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 28,
            "citationCount": 496,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 26,
            "citationCount": 84,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 52,
            "citationCount": 195,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 22,
            "citationCount": 259,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 15,
            "citationCount": 177,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 24,
            "citationCount": 1835,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 1,
    "embedding": null
}