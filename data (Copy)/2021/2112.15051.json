{
    "arxiv_id": "2112.15051",
    "title": "Does QA-based intermediate training help fine-tuning language models for text classification?",
    "authors": [
        {
            "name": "S Zhang",
            "citations_all": 302,
            "citations_recent": 275,
            "h_index_all": 8,
            "h_index_recent": 7,
            "i10_index_all": 6,
            "i10_index_recent": 6
        },
        {
            "name": "XJ Zhang",
            "citations_all": 5177,
            "citations_recent": 2709,
            "h_index_all": 36,
            "h_index_recent": 28,
            "i10_index_all": 89,
            "i10_index_recent": 61
        }
    ],
    "abstract": "Fine-tuning pre-trained language models for downstream tasks has become a norm for NLP. Recently it is found that intermediate training based on high-level inference tasks such as Question Answering (QA) can improve the performance of some language models for target tasks. However it is not clear if intermediate training generally benefits various language models. In this paper, using the SQuAD-2.0 QA task for intermediate training for target text classification tasks, we experimented on eight tasks for single-sequence classification and eight tasks for sequence-pair classification using two base and two compact language models. Our experiments show that QA-based intermediate training generates varying transfer performance across different language models, except for similar QA tasks.",
    "published_date": "2021-12-30T00:00:00",
    "last_revised_date": "2021-12-30T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2112.15051.pdf",
    "primary_category": "Computation and Language (cs.CL)",
    "categories": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
    ],
    "keywords": null,
    "num_pages": 5,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2022": 1,
        "2024": 1
    },
    "citationCount": 2,
    "venue": {
        "name": "Australasian Language Technology Association Workshop",
        "type": "conference"
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 46,
            "citationCount": 1,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 98,
            "citationCount": 73,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 21,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 33,
            "citationCount": 819,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 104,
            "citationCount": 133,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 146,
            "citationCount": 49781,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 62,
            "citationCount": 179,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 60,
            "citationCount": 204,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 77,
            "citationCount": 2653,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 67,
            "citationCount": 885,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 134,
            "citationCount": 22913,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 68,
            "citationCount": 27065,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 39,
            "citationCount": 1655,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 86,
            "citationCount": 2530,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 32,
            "citationCount": 476,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 25,
            "citationCount": 3065,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 77,
            "citationCount": 7806,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 16,
            "citationCount": 1512,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 10,
            "citationCount": 978,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 32,
            "citationCount": 6534,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 0,
            "citationCount": 535,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 63,
            "citationCount": 104943,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 0,
            "citationCount": 123,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 0,
    "embedding": null
}