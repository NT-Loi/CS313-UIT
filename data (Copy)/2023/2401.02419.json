{
    "arxiv_id": "2401.02419",
    "title": "Moving Object Based Collision-Free Video Synopsis",
    "authors": [
        {
            "name": "AJ Ratnarajah",
            "citations_all": 422,
            "citations_recent": 421,
            "h_index_all": 10,
            "h_index_recent": 10,
            "i10_index_all": 10,
            "i10_index_recent": 10
        },
        {
            "name": "S Goonetilleke",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "D Tissera",
            "citations_all": 51,
            "citations_recent": 47,
            "h_index_all": 5,
            "h_index_recent": 5,
            "i10_index_all": 2,
            "i10_index_recent": 1
        },
        {
            "name": "K Balagopalan",
            "citations_all": 9,
            "citations_recent": 8,
            "h_index_all": 2,
            "h_index_recent": 2,
            "i10_index_all": 0,
            "i10_index_recent": 0
        },
        {
            "name": "R Rodrigo",
            "citations_all": 1646,
            "citations_recent": 1272,
            "h_index_all": 17,
            "h_index_recent": 13,
            "i10_index_all": 23,
            "i10_index_recent": 14
        }
    ],
    "abstract": "Video synopsis, summarizing a video to generate a shorter video by exploiting the spatial and temporal redundancies, is important for surveillance and archiving. Existing trajectory-based video synopsis algorithms will not able to work in real time, because of the complexity due to the number of object tubes that need to be included in the complex energy minimization algorithm. We propose a real-time algorithm by using a method that incrementally stitches each frame of the synopsis by extracting object frames from the user specified number of tubes in the buffer in contrast to global energy-minimization based systems. This also gives flexibility to the user to set the threshold of maximum number of objects in the synopsis video according his or her tracking ability and creates collision-free summarized videos which are visually pleasing. Experiments with six common test videos, indoors and outdoors with many moving objects, show that the proposed video synopsis algorithm produces better frame reduction rates than existing approaches.",
    "published_date": "2023-09-17T00:00:00",
    "last_revised_date": "2023-09-17T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2401.02419.pdf",
    "primary_category": "Computer Vision and Pattern Recognition (cs.CV)",
    "categories": [
        "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "keywords": null,
    "num_pages": 7,
    "github_stars": null,
    "upvote": 1,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 1,
    "citations_by_year": {
        "2021": 3,
        "2024": 1
    },
    "citationCount": 5,
    "venue": {
        "name": "IEEE International Conference on Systems, Man and Cybernetics",
        "type": "conference",
        "ranking": "B"
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 14,
            "citationCount": 3,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 14,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 71,
            "citationCount": 32,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 11,
            "citationCount": 12,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 64,
            "citationCount": 40,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 28,
            "citationCount": 21,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 48,
            "citationCount": 71,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 31,
            "citationCount": 74,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 14,
            "citationCount": 22,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 19,
            "citationCount": 7,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 20,
            "citationCount": 272,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 29,
            "citationCount": 1617,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 14,
            "citationCount": 2529,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 24,
            "citationCount": 155,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 9,
            "citationCount": 480,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 25,
            "citationCount": 26,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 0,
    "embedding": null
}