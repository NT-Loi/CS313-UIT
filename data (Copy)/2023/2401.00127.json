{
    "arxiv_id": "2401.00127",
    "title": "Pushing Boundaries: Exploring Zero Shot Object Classification with Large Multimodal Models",
    "authors": [
        {
            "name": "A Islam",
            "citations_all": 302,
            "citations_recent": 301,
            "h_index_all": 8,
            "h_index_recent": 8,
            "i10_index_all": 7,
            "i10_index_recent": 7
        },
        {
            "name": "MR Biswas",
            "citations_all": 579,
            "citations_recent": 567,
            "h_index_all": 9,
            "h_index_recent": 9,
            "i10_index_all": 9,
            "i10_index_recent": 9
        },
        {
            "name": "W Zaghouani",
            "citations_all": 3891,
            "citations_recent": 2745,
            "h_index_all": 35,
            "h_index_recent": 27,
            "i10_index_all": 73,
            "i10_index_recent": 57
        },
        {
            "name": "SB Belhaouari",
            "citations_all": 4659,
            "citations_recent": 3434,
            "h_index_all": 36,
            "h_index_recent": 30,
            "i10_index_all": 114,
            "i10_index_recent": 97
        },
        {
            "name": "Z Shah",
            "citations_all": 4128,
            "citations_recent": 4011,
            "h_index_all": 29,
            "h_index_recent": 29,
            "i10_index_all": 51,
            "i10_index_recent": 50
        }
    ],
    "abstract": "$ $The synergy of language and vision models has given rise to Large Language and Vision Assistant models (LLVAs), designed to engage users in rich conversational experiences intertwined with image-based queries. These comprehensive multimodal models seamlessly integrate vision encoders with Large Language Models (LLMs), expanding their applications in general-purpose language and visual comprehension. The advent of Large Multimodal Models (LMMs) heralds a new era in Artificial Intelligence (AI) assistance, extending the horizons of AI utilization. This paper takes a unique perspective on LMMs, exploring their efficacy in performing image classification tasks using tailored prompts designed for specific datasets. We also investigate the LLVAs zero-shot learning capabilities. Our study includes a benchmarking analysis across four diverse datasets: MNIST, Cats Vs. Dogs, Hymnoptera (Ants Vs. Bees), and an unconventional dataset comprising Pox Vs. Non-Pox skin images. The results of our experiments demonstrate the model's remarkable performance, achieving classification accuracies of 85\\%, 100\\%, 77\\%, and 79\\% for the respective datasets without any fine-tuning. To bolster our analysis, we assess the model's performance post fine-tuning for specific tasks. In one instance, fine-tuning is conducted over a dataset comprising images of faces of children with and without autism. Prior to fine-tuning, the model demonstrated a test accuracy of 55\\%, which significantly improved to 83\\% post fine-tuning. These results, coupled with our prior findings, underscore the transformative potential of LLVAs and their versatile applications in real-world scenarios.",
    "published_date": "2023-12-30T00:00:00",
    "last_revised_date": "2023-12-30T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2401.00127.pdf",
    "primary_category": "Computer Vision and Pattern Recognition (cs.CV)",
    "categories": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Social and Information Networks (cs.SI)"
    ],
    "keywords": null,
    "num_pages": 5,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2024": 4,
        "2025": 6
    },
    "citationCount": 10,
    "venue": {
        "name": "International Conference on Social Networks Analysis, Management and Security",
        "type": "conference"
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 259,
            "citationCount": 37,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 17,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 121,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 15,
            "citationCount": 2,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 15,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 71,
            "citationCount": 3564,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 14,
            "citationCount": 23,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 20,
            "citationCount": 212,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 23,
            "citationCount": 99,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 30,
            "citationCount": 3,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 63,
            "citationCount": 6241,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 36,
            "citationCount": 118,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 43,
            "citationCount": 2399,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 7,
            "citationCount": 4996,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 0,
    "embedding": null
}