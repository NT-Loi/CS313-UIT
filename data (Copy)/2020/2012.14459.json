{
    "arxiv_id": "2012.14459",
    "title": "Enhancing Handwritten Text Recognition with N-gram sequence decomposition and Multitask Learning",
    "authors": [
        {
            "name": "V Tassopoulou",
            "citations_all": 129,
            "citations_recent": 129,
            "h_index_all": 4,
            "h_index_recent": 4,
            "i10_index_all": 2,
            "i10_index_recent": 2
        },
        {
            "name": "G Retsinas",
            "citations_all": 1051,
            "citations_recent": 949,
            "h_index_all": 18,
            "h_index_recent": 16,
            "i10_index_all": 28,
            "i10_index_recent": 26
        },
        {
            "name": "P Maragos",
            "citations_all": 22808,
            "citations_recent": 5738,
            "h_index_all": 70,
            "h_index_recent": 36,
            "i10_index_all": 313,
            "i10_index_recent": 162
        }
    ],
    "abstract": "Current state-of-the-art approaches in the field of Handwritten Text Recognition are predominately single task with unigram, character level target units. In our work, we utilize a Multi-task Learning scheme, training the model to perform decompositions of the target sequence with target units of different granularity, from fine to coarse. We consider this method as a way to utilize n-gram information, implicitly, in the training process, while the final recognition is performed using only the unigram output. % in order to highlight the difference of the internal Unigram decoding of such a multi-task approach highlights the capability of the learned internal representations, imposed by the different n-grams at the training step. We select n-grams as our target units and we experiment from unigrams to fourgrams, namely subword level granularities. These multiple decompositions are learned from the network with task-specific CTC losses. Concerning network architectures, we propose two alternatives, namely the Hierarchical and the Block Multi-task. Overall, our proposed model, even though evaluated only on the unigram task, outperforms its counterpart single-task by absolute 2.52\\% WER and 1.02\\% CER, in the greedy decoding, without any computational overhead during inference, hinting towards successfully imposing an implicit language model.",
    "published_date": "2020-12-28T00:00:00",
    "last_revised_date": "2020-12-28T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2012.14459.pdf",
    "primary_category": "Computer Vision and Pattern Recognition (cs.CV)",
    "categories": [
        "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "keywords": null,
    "num_pages": 6,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2021": 4,
        "2022": 4,
        "2023": 4,
        "2024": 10,
        "2025": 1
    },
    "citationCount": 23,
    "venue": {
        "name": "International Conference on Pattern Recognition",
        "type": "conference",
        "ranking": "B"
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 61,
            "citationCount": 1,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 48,
            "citationCount": 4,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 35,
            "citationCount": 1,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 31,
            "citationCount": 7,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 33,
            "citationCount": 25,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 45,
            "citationCount": 1,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 50,
            "citationCount": 10,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 19,
            "citationCount": 2,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 27,
            "citationCount": 1,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 36,
            "citationCount": 5,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 26,
            "citationCount": 4,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 42,
            "citationCount": 36,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 59,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 74,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 29,
            "citationCount": 6,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 47,
            "citationCount": 4,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 26,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 43,
            "citationCount": 118,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 28,
            "citationCount": 25,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 12,
            "citationCount": 73,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 28,
            "citationCount": 83,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 36,
            "citationCount": 44,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 27,
            "citationCount": 33,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 19,
            "citationCount": 247,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 26,
            "citationCount": 127,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 34,
            "citationCount": 56,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 41,
            "citationCount": 62,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 32,
            "citationCount": 197,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 33,
            "citationCount": 24,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 24,
            "citationCount": 172,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 41,
            "citationCount": 20965,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 23,
            "citationCount": 2224,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 39,
            "citationCount": 571,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 22,
            "citationCount": 1528,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 0,
            "citationCount": 123,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 18,
            "citationCount": 4655,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 14,
            "citationCount": 892,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 23,
            "citationCount": 1425,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 26,
            "citationCount": 486,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 48,
            "citationCount": 95526,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 38,
            "citationCount": 192,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 1,
            "citationCount": 807,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 20,
            "citationCount": 510,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 0,
    "embedding": null
}