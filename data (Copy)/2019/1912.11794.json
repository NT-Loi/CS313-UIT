{
    "arxiv_id": "1912.11794",
    "title": "Performance benefits of Intel(R) OptaneTM DC persistent memory for the parallel processing of large neuroimaging data",
    "authors": [
        {
            "name": "V Hayot-Sasson",
            "error": "invalid literal for int() with base 10: ''"
        },
        {
            "name": "ST Brown",
            "error": "invalid literal for int() with base 10: ''"
        },
        {
            "name": "T Glatard",
            "error": "invalid literal for int() with base 10: ''"
        }
    ],
    "abstract": "Open-access neuroimaging datasets have reached petabyte scale, and continue to grow. The ability to leverage the entirety of these datasets is limited to a restricted number of labs with both the capacity and infrastructure to process the data. Whereas Big Data engines have significantly reduced application performance penalties with respect to data movement, their applied strategies (e.g. data locality, in-memory computing and lazy evaluation) are not necessarily practical within neuroimaging workflows where intermediary results may need to be materialized to shared storage for post-processing analysis. In this paper we evaluate the performance advantage brought by Intel(R) OptaneTM DC persistent memory for the processing of large neuroimaging datasets using the two available configurations modes: Memory mode and App Direct mode. We employ a synthetic algorithm on the 76 GiB and 603 GiB BigBrain, as well as apply a standard neuroimaging application on the Consortium for Reliability and Reproducibility (CoRR) dataset using 25 and 96 parallel processes in both cases. Our results show that the performance of applications leveraging persistent memory is superior to that of other storage devices,with the exception of DRAM. This is the case in both Memory and App Direct mode and irrespective of the amount of data and parallelism. Furthermore, persistent memory in App Direct mode is believed to benefit from the use of DRAM as a cache for writing when output data is significantly smaller than available memory. We believe the use of persistent memory will be beneficial to both neuroimaging applications running on HPC or visualization of large, high-resolution images.",
    "published_date": "2019-12-26T00:00:00",
    "last_revised_date": "2019-12-26T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/1912.11794.pdf",
    "primary_category": "Performance (cs.PF)",
    "categories": [
        "Performance (cs.PF)"
    ],
    "keywords": null,
    "num_pages": 10,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {},
    "citationCount": 0,
    "venue": {
        "name": "IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing",
        "type": "conference",
        "ranking": "B"
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 16,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 40,
            "citationCount": 3,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 41,
            "citationCount": 3,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 50,
            "citationCount": 9,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 13,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 13,
            "citationCount": 332,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 36,
            "citationCount": 1517,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 47,
            "citationCount": 23,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 91,
            "citationCount": 432,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 81,
            "citationCount": 5223,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 50,
            "citationCount": 795,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 0,
            "citationCount": 1263,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 44,
            "citationCount": 26057,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 5,
            "citationCount": 435,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 0,
    "embedding": null
}