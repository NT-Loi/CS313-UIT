{
    "arxiv_id": "2212.14828",
    "title": "Informing selection of performance metrics for medical image segmentation evaluation using configurable synthetic errors",
    "authors": [
        {
            "name": "S Guan",
            "citations_all": 1266,
            "citations_recent": 1248,
            "h_index_all": 15,
            "h_index_recent": 15,
            "i10_index_all": 16,
            "i10_index_recent": 16
        },
        {
            "name": "RK Samala",
            "citations_all": 5271,
            "citations_recent": 4429,
            "h_index_all": 29,
            "h_index_recent": 26,
            "i10_index_all": 46,
            "i10_index_recent": 38
        },
        {
            "name": "W Chen",
            "citations_all": 4687,
            "citations_recent": 2208,
            "h_index_all": 25,
            "h_index_recent": 21,
            "i10_index_all": 40,
            "i10_index_recent": 33
        }
    ],
    "abstract": "Machine learning-based segmentation in medical imaging is widely used in clinical applications from diagnostics to radiotherapy treatment planning. Segmented medical images with ground truth are useful for investigating the properties of different segmentation performance metrics to inform metric selection. Regular geometrical shapes are often used to synthesize segmentation errors and illustrate properties of performance metrics, but they lack the complexity of anatomical variations in real images. In this study, we present a tool to emulate segmentations by adjusting the reference (truth) masks of anatomical objects extracted from real medical images. Our tool is designed to modify the defined truth contours and emulate different types of segmentation errors with a set of user-configurable parameters. We defined the ground truth objects from 230 patient images in the Glioma Image Segmentation for Radiotherapy (GLIS-RT) database. For each object, we used our segmentation synthesis tool to synthesize 10 versions of segmentation (i.e., 10 simulated segmentors or algorithms), where each version has a pre-defined combination of segmentation errors. We then applied 20 performance metrics to evaluate all synthetic segmentations. We demonstrated the properties of these metrics, including their ability to capture specific types of segmentation errors. By analyzing the intrinsic properties of these metrics and categorizing the segmentation errors, we are working toward the goal of developing a decision-tree tool for assisting in the selection of segmentation performance metrics.",
    "published_date": "2022-12-30T00:00:00",
    "last_revised_date": "2022-12-30T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2212.14828.pdf",
    "primary_category": "Image and Video Processing (eess.IV)",
    "categories": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "keywords": null,
    "num_pages": 8,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2024": 2
    },
    "citationCount": 2,
    "venue": {
        "name": "International Conference on Artificial Intelligence and Pattern Recognition",
        "type": "conference",
        "ranking": "A"
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 15,
            "citationCount": 0,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 11,
            "citationCount": 1,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 12,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 20,
            "citationCount": 60,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 23,
            "citationCount": 13,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 97,
            "citationCount": 1382,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 82,
            "citationCount": 2272,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 23,
            "citationCount": 26,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 21,
            "citationCount": 33,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 65,
            "citationCount": 2135,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 0,
            "citationCount": 118,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 73,
            "citationCount": 455,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 0,
            "citationCount": 168645,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 44,
            "citationCount": 98208,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 0,
    "embedding": null
}