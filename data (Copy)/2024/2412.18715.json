{
    "arxiv_id": "2412.18715",
    "title": "Optimization and Scalability of Collaborative Filtering Algorithms in Large Language Models",
    "authors": [
        {
            "name": "H Yang",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "L Yun",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "J Cao",
            "citations_all": 77,
            "citations_recent": 77,
            "h_index_all": 4,
            "h_index_recent": 4,
            "i10_index_all": 4,
            "i10_index_recent": 4
        },
        {
            "name": "Q Lu",
            "citations_all": 141,
            "citations_recent": 141,
            "h_index_all": 8,
            "h_index_recent": 8,
            "i10_index_all": 8,
            "i10_index_recent": 8
        },
        {
            "name": "Y Tu",
            "citations_all": 56,
            "citations_recent": 56,
            "h_index_all": 3,
            "h_index_recent": 3,
            "i10_index_all": 3,
            "i10_index_recent": 3
        }
    ],
    "abstract": "With the rapid development of large language models (LLMs) and the growing demand for personalized content, recommendation systems have become critical in enhancing user experience and driving engagement. Collaborative filtering algorithms, being core to many recommendation systems, have garnered significant attention for their efficiency and interpretability. However, traditional collaborative filtering approaches face numerous challenges when integrated into large-scale LLM-based systems, including high computational costs, severe data sparsity, cold start problems, and lack of scalability. This paper investigates the optimization and scalability of collaborative filtering algorithms in large language models, addressing these limitations through advanced optimization strategies. Firstly, we analyze the fundamental principles of collaborative filtering algorithms and their limitations when applied in LLM-based contexts. Next, several optimization techniques such as matrix factorization, approximate nearest neighbor search, and parallel computing are proposed to enhance computational efficiency and model accuracy. Additionally, strategies such as distributed architecture and model compression are explored to facilitate dynamic updates and scalability in data-intensive environments.",
    "published_date": "2024-12-25T00:00:00",
    "last_revised_date": "2024-12-25T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/2412.18715.pdf",
    "primary_category": "Artificial Intelligence (cs.AI)",
    "categories": [
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
    ],
    "keywords": null,
    "num_pages": 10,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2025": 16
    },
    "citationCount": 16,
    "venue": {
        "name": null,
        "type": null,
        "ranking": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 53,
            "citationCount": 2,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 18,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 0,
            "citationCount": 8,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 0,
            "citationCount": 11,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 0,
            "citationCount": 10,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 0,
            "citationCount": 13,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 30,
            "citationCount": 10,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 25,
            "citationCount": 8,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 9,
            "citationCount": 11,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 34,
            "citationCount": 14,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 20,
            "citationCount": 7,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 20,
            "citationCount": 9,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 5,
            "citationCount": 8,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 44,
            "citationCount": 21,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 12,
            "citationCount": 11,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 25,
            "citationCount": 18,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 16,
            "citationCount": 14,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 13,
            "citationCount": 30,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 9,
            "citationCount": 16,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 12,
            "citationCount": 33,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 0,
    "embedding": null
}