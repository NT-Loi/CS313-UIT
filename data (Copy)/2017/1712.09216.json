{
    "arxiv_id": "1712.09216",
    "title": "Large-Scale 3D Scene Classification With Multi-View Volumetric CNN",
    "authors": [
        {
            "name": "D Aiger",
            "citations_all": 2802,
            "citations_recent": 1478,
            "h_index_all": 16,
            "h_index_recent": 9,
            "i10_index_all": 18,
            "i10_index_recent": 9
        },
        {
            "name": "B Allen",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        },
        {
            "name": "A Golovinskiy",
            "citations_all": null,
            "citations_recent": null,
            "h_index_all": null,
            "h_index_recent": null,
            "i10_index_all": null,
            "i10_index_recent": null
        }
    ],
    "abstract": "We introduce a method to classify imagery using a convo- lutional neural network (CNN) on multi-view image pro- jections. The power of our method comes from using pro- jections of multiple images at multiple depth planes near the reconstructed surface. This enables classification of categories whose salient aspect is appearance change un- der different viewpoints, such as water, trees, and other materials with complex reflection/light response proper- ties. Our method does not require boundary labelling in images and works on pixel-level classification with a small (few pixels) context, which simplifies the cre- ation of a training set. We demonstrate this application on large-scale aerial imagery collections, and extend the per-pixel classification to robustly create a consistent 2D classification which can be used to fill the gaps in non- reconstructible water regions. We also apply our method to classify tree regions. In both cases, the training data can quickly be generated using a small number of manually- created polygons on a map. We show that even with a very simple and standard network our CNN outperforms the state-of-the-art image classification, the Inception-V3 model retrained from a large collection of aerial images.",
    "published_date": "2017-12-26T00:00:00",
    "last_revised_date": "2017-12-26T00:00:00",
    "num_revisions": 0,
    "pdf_url": "https://arxiv.org/pdf/1712.09216.pdf",
    "primary_category": "Computer Vision and Pattern Recognition (cs.CV)",
    "categories": [
        "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "keywords": null,
    "num_pages": 11,
    "github_stars": null,
    "upvote": 0,
    "citing_models": 0,
    "citing_datasets": 0,
    "citing_spaces": 0,
    "citing_collections": 0,
    "citations_by_year": {
        "2019": 1,
        "2021": 2,
        "2022": 1,
        "2023": 1,
        "2024": 2
    },
    "citationCount": 7,
    "venue": {
        "name": "arXiv.org",
        "type": null,
        "ranking": null
    },
    "citations": [
        {
            "arxiv_id": null,
            "referenceCount": 192,
            "citationCount": 33,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 154,
            "citationCount": 39,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 52,
            "citationCount": 1,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 80,
            "citationCount": 5,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 35,
            "citationCount": 19,
            "influentialCitationCount": null
        }
    ],
    "referenceCount": 22,
    "references": [
        {
            "arxiv_id": null,
            "referenceCount": 92,
            "citationCount": 18723,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 37,
            "citationCount": 1585,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 24,
            "citationCount": 28297,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 40,
            "citationCount": 620,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 50,
            "citationCount": 1007,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 46,
            "citationCount": 19166,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 15,
            "citationCount": 320,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 69,
            "citationCount": 38870,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 264,
            "citationCount": 44561,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 23,
            "citationCount": 782,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 43,
            "citationCount": 103237,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 71,
            "citationCount": 92,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 28,
            "citationCount": 246,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 71,
            "citationCount": 123064,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 62,
            "citationCount": 2759,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 59,
            "citationCount": 8300,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 38,
            "citationCount": 40817,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 5,
            "citationCount": 11,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": null,
            "citationCount": null,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 0,
            "citationCount": 4374,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 10,
            "citationCount": 2200,
            "influentialCitationCount": null
        },
        {
            "arxiv_id": null,
            "referenceCount": 150,
            "citationCount": 56481,
            "influentialCitationCount": null
        }
    ],
    "influentialCitationCount": 0,
    "embedding": null
}